import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from gensim.models import Word2Vec, Doc2Vec
import json
import os
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

def load_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞–∫ Doc2Vec –º–æ–¥–µ–ª—å
        model = Doc2Vec.load("doc2vec_pv-dm_20251023_181820.model")
        st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å Doc2Vec –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return model
    except:
        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞–∫ Word2Vec –º–æ–¥–µ–ª—å
            model = Word2Vec.load("doc2vec_pv-dm_20251023_181820.model")
            st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å Word2Vec –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return model
        except:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π —Å—É—â–µ—Å—Ç–≤—É—é—Ç:")
            st.code("""
–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
- doc2vec_pv-dm_20251023_181820.model (Doc2Vec)
- word2vec_cbow.model (Word2Vec)
- word2vec_skipgram.model (Word2Vec)
            """)
            return None

def load_model_metadata():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏"""
    try:
        with open("/home/ilnaz/code/NLP/lab2/doc2vec_pv-dm_20251023_181820_metadata.json", 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {"error": "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"}

def vector_arithmetic_interface(model):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∏"""
    st.header("üî¢ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞")
    
    if model is None:
        st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return
    
    expression = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: –∫–∞–∑–∞–Ω - —Ç–∞—Ç–∞—Ä—Å—Ç–∞–Ω + —Ä–æ—Å—Å–∏—è):")
    
    if expression:
        try:
            words = expression.split()
            positives = []
            negatives = []
            
            # –ü–∞—Ä—Å–∏–º –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
            i = 0
            while i < len(words):
                if words[i] == '+':
                    if i+1 < len(words):
                        positives.append(words[i+1])
                    i += 2
                elif words[i] == '-':
                    if i+1 < len(words):
                        negatives.append(words[i+1])
                    i += 2
                else:
                    positives.append(words[i])
                    i += 1
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤ –≤ –º–æ–¥–µ–ª–∏
            missing_words = []
            for word in positives + negatives:
                if word not in model.wv:
                    missing_words.append(word)
            
            if missing_words:
                st.error(f"–°–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –º–æ–¥–µ–ª–∏: {missing_words}")
                return
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫—É
            result = model.wv.most_similar(positive=positives, negative=negatives, topn=10)
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç:")
            df = pd.DataFrame(result, columns=['–°–ª–æ–≤–æ', '–°—Ö–æ–¥—Å—Ç–≤–æ'])
            st.dataframe(df)
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            fig, ax = plt.subplots(figsize=(10, 6))
            words_plot = [word for word, _ in result[:8]]
            similarities = [sim for _, sim in result[:8]]
            
            ax.barh(words_plot, similarities, color='skyblue')
            ax.set_xlabel('–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ')
            ax.set_title('–¢–æ–ø-8 –±–ª–∏–∂–∞–π—à–∏—Ö —Å–ª–æ–≤')
            st.pyplot(fig)
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")

def similarity_analysis_interface(model):
    """–ê–Ω–∞–ª–∏–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
    st.header("üìä –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–¥—Å—Ç–≤–∞")
    
    if model is None:
        st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return
    
    col1, col2 = st.columns(2)
    
    with col1:
        word1 = st.text_input("–°–ª–æ–≤–æ 1:", "–º–∞—Ç–±—É–≥–∞—Ç")
    with col2:
        word2 = st.text_input("–°–ª–æ–≤–æ 2:", "—Ö–µ–∑–º”ô—Ç–µ")
    
    if word1 and word2:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤
            if word1 not in model.wv:
                st.error(f"–°–ª–æ–≤–æ '{word1}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –º–æ–¥–µ–ª–∏")
                return
            if word2 not in model.wv:
                st.error(f"–°–ª–æ–≤–æ '{word2}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –º–æ–¥–µ–ª–∏")
                return
            
            similarity = model.wv.similarity(word1, word2)
            st.metric("–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ", f"{similarity:.4f}")
            
            # –ë–ª–∏–∂–∞–π—à–∏–µ —Å–æ—Å–µ–¥–∏ –¥–ª—è –æ–±–æ–∏—Ö —Å–ª–æ–≤
            neighbors1 = model.wv.most_similar(word1, topn=10)
            neighbors2 = model.wv.most_similar(word2, topn=10)
            
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"–°–æ—Å–µ–¥–∏ **{word1}**:")
                df1 = pd.DataFrame(neighbors1, columns=['–°–ª–æ–≤–æ', '–°—Ö–æ–¥—Å—Ç–≤–æ'])
                st.dataframe(df1)
            
            with col2:
                st.write(f"–°–æ—Å–µ–¥–∏ **{word2}**:")
                df2 = pd.DataFrame(neighbors2, columns=['–°–ª–æ–≤–æ', '–°—Ö–æ–¥—Å—Ç–≤–æ'])
                st.dataframe(df2)
                
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")

def semantic_axes_interface(model):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Å–µ–π"""
    st.header("üìà –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–∏")
    
    if model is None:
        st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return
    
    st.info("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–æ–≤–∞ –∏–∑ –≤–∞—à–µ–≥–æ –∫–æ—Ä–ø—É—Å–∞: –º–∞—Ç–±—É–≥–∞—Ç, —Ö–µ–∑–º”ô—Ç–µ, —Ö–æ–∫—É–∫, —Å–∞–∫–ª–∞—É, —ç—á–∫–µ, —ç—à–ª”ô—Ä –∏ —Ç.–¥.")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        pos1 = st.text_input("–ü–æ–ª—é—Å 1+", "–º–∞—Ç–±—É–≥–∞—Ç")
    with col2:
        pos2 = st.text_input("–ü–æ–ª—é—Å 2+", "—Ö–µ–∑–º”ô—Ç–µ")
    with col3:
        neg1 = st.text_input("–ü–æ–ª—é—Å 1-", "—Ö–æ–∫—É–∫")
    with col4:
        neg2 = st.text_input("–ü–æ–ª—é—Å 2-", "—Å–∞–∫–ª–∞—É")
    
    test_words = st.text_area("–°–ª–æ–≤–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):", 
                             "—ç—á–∫–µ, —ç—à–ª”ô—Ä, —Ö”ô–±”ô—Ä, –∏—Ç”ô, —Å—É–º, —Ç”ô—à–∫–∏–ª")
    
    if st.button("–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –æ—Å—å"):
        try:
            # –í—ã—á–∏—Å–ª—è–µ–º –æ—Å—å
            pos_words = [w for w in [pos1, pos2] if w in model.wv]
            neg_words = [w for w in [neg1, neg2] if w in model.wv]
            
            if not pos_words:
                st.error("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—é—Å—ã")
                return
            if not neg_words:
                st.error("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—é—Å—ã")
                return
            
            pos_vecs = [model.wv[w] for w in pos_words]
            neg_vecs = [model.wv[w] for w in neg_words]
            
            axis = np.mean(pos_vecs, axis=0) - np.mean(neg_vecs, axis=0)
            axis = axis / np.linalg.norm(axis)
            
            # –ü—Ä–æ–µ—Ü–∏—Ä—É–µ–º —Å–ª–æ–≤–∞
            words_to_test = [w.strip() for w in test_words.split(',')]
            projections = {}
            
            for word in words_to_test:
                if word in model.wv:
                    projections[word] = np.dot(model.wv[word], axis)
            
            if not projections:
                st.error("–ù–∏ –æ–¥–Ω–æ –∏–∑ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –º–æ–¥–µ–ª–∏")
                return
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º
            sorted_projections = sorted(projections.items(), key=lambda x: x[1])
            
            fig, ax = plt.subplots(figsize=(12, 8))
            words = [item[0] for item in sorted_projections]
            values = [item[1] for item in sorted_projections]
            colors = ['red' if v < 0 else 'green' for v in values]
            
            ax.barh(words, values, color=colors, alpha=0.6)
            ax.axvline(0, color='black', linestyle='--', alpha=0.5)
            ax.set_xlabel('–ü—Ä–æ–µ–∫—Ü–∏—è –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –æ—Å—å')
            ax.set_title(f'–û—Å—å: {"+".join(pos_words)} - {"+".join(neg_words)}')
            ax.grid(axis='x', alpha=0.3)
            
            st.pyplot(fig)
            
            # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            df = pd.DataFrame(sorted_projections, columns=['–°–ª–æ–≤–æ', '–ü—Ä–æ–µ–∫—Ü–∏—è'])
            st.dataframe(df)
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")

def visualization_interface(model):
    """2D/3D –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è"""
    st.header("üé® 2D/3D –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")
    
    if model is None:
        st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return
    
    words_input = st.text_area("–°–ª–æ–≤–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é):",
                              "–º–∞—Ç–±—É–≥–∞—Ç, —Ö–µ–∑–º”ô—Ç–µ, —Ö–æ–∫—É–∫, —Å–∞–∫–ª–∞—É, —ç—á–∫–µ, —ç—à–ª”ô—Ä, —Ö”ô–±”ô—Ä, –∏—Ç”ô")
    
    method = st.selectbox("–ú–µ—Ç–æ–¥ –ø—Ä–æ–µ–∫—Ü–∏–∏:", ["PCA", "t-SNE"])
    dimensions = st.radio("–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å:", [2, 3])
    
    if st.button("–í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å"):
        try:
            words = [w.strip() for w in words_input.split(',')]
            available_words = [w for w in words if w in model.wv]
            
            if len(available_words) < 3:
                st.error(f"–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 —Å–ª–æ–≤–∞. –ù–∞–π–¥–µ–Ω–æ: {available_words}")
                return
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã
            vectors = np.array([model.wv[word] for word in available_words])
            
            # –ü—Ä–æ–µ–∫—Ü–∏—è
            if method == "PCA":
                projector = PCA(n_components=dimensions)
            else:
                projector = TSNE(n_components=dimensions, random_state=42, perplexity=min(5, len(available_words)-1))
            
            projected = projector.fit_transform(vectors)
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            if dimensions == 2:
                fig, ax = plt.subplots(figsize=(12, 10))
                scatter = ax.scatter(projected[:, 0], projected[:, 1], alpha=0.7, s=100)
                
                for i, word in enumerate(available_words):
                    ax.annotate(word, (projected[i, 0], projected[i, 1]),
                               xytext=(5, 5), textcoords='offset points')
                
                ax.set_xlabel('Component 1')
                ax.set_ylabel('Component 2')
                ax.set_title(f'{method} –ø—Ä–æ–µ–∫—Ü–∏—è —Å–ª–æ–≤')
                ax.grid(alpha=0.3)
                
            else:  # 3D
                fig = plt.figure(figsize=(12, 10))
                ax = fig.add_subplot(111, projection='3d')
                scatter = ax.scatter(projected[:, 0], projected[:, 1], projected[:, 2], 
                                   alpha=0.7, s=100)
                
                for i, word in enumerate(available_words):
                    ax.text(projected[i, 0], projected[i, 1], projected[i, 2], word)
                
                ax.set_xlabel('Component 1')
                ax.set_ylabel('Component 2')
                ax.set_zlabel('Component 3')
                ax.set_title(f'{method} –ø—Ä–æ–µ–∫—Ü–∏—è —Å–ª–æ–≤')
            
            st.pyplot(fig)
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")

def analogy_test_interface(model):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–æ–≥–∏–π"""
    st.header("üß† –¢–µ—Å—Ç –∞–Ω–∞–ª–æ–≥–∏–π")
    
    if model is None:
        st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        return
    
    analogy = st.text_input("–ê–Ω–∞–ª–æ–≥–∏—è (—Ñ–æ—Ä–º–∞—Ç: —Å–ª–æ–≤–æ1 —Å–ª–æ–≤–æ2 —Å–ª–æ–≤–æ3 –æ—Ç–≤–µ—Ç):", 
                           "–∫–∞–∑–∞–Ω —Ç–∞—Ç–∞—Ä—Å—Ç–∞–Ω —Ä–æ—Å—Å–∏—è –º”ô—Å–∫”ô“Ø")
    
    if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–Ω–∞–ª–æ–≥–∏—é"):
        try:
            words = analogy.split()
            if len(words) != 4:
                st.error("–ù—É–∂–Ω–æ 4 —Å–ª–æ–≤–∞")
                return
            
            a, b, c, expected = words
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–ª–æ–≤
            missing = [w for w in [a, b, c, expected] if w not in model.wv]
            if missing:
                st.error(f"–°–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {missing}")
                return
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∞–Ω–∞–ª–æ–≥–∏—é
            result = model.wv.most_similar(positive=[b, c], negative=[a], topn=5)
            
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç:")
            df = pd.DataFrame(result, columns=['–°–ª–æ–≤–æ', '–°—Ö–æ–¥—Å—Ç–≤–æ'])
            st.dataframe(df)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
            predicted_words = [word for word, _ in result]
            is_correct = expected in predicted_words
            
            if is_correct:
                position = predicted_words.index(expected) + 1
                st.success(f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ! –°–ª–æ–≤–æ '{expected}' –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ {position}")
            else:
                st.error(f"‚ùå –û–∂–∏–¥–∞–ª–æ—Å—å: '{expected}'")
                
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤", layout="wide")
    st.title("üîç –ê–Ω–∞–ª–∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤ —Ç–∞—Ç–∞—Ä—Å–∫–æ–≥–æ —è–∑—ã–∫–∞")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏..."):
        model = load_model()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    metadata = load_model_metadata()
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π
    st.sidebar.title("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
    section = st.sidebar.radio("–†–∞–∑–¥–µ–ª:", [
        "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞",
        "–ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–¥—Å—Ç–≤–∞", 
        "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–∏",
        "2D/3D –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è",
        "–¢–µ—Å—Ç –∞–Ω–∞–ª–æ–≥–∏–π"
    ])
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞
    if section == "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –∞—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞":
        vector_arithmetic_interface(model)
    elif section == "–ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–¥—Å—Ç–≤–∞":
        similarity_analysis_interface(model)
    elif section == "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–∏":
        semantic_axes_interface(model)
    elif section == "2D/3D –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è":
        visualization_interface(model)
    elif section == "–¢–µ—Å—Ç –∞–Ω–∞–ª–æ–≥–∏–π":
        analogy_test_interface(model)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
    st.sidebar.markdown("---")
    st.sidebar.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")
    
    if model is not None:
        st.sidebar.write(f"–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {len(model.wv.key_to_index):,}")
        st.sidebar.write(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {model.wv.vector_size}")
        st.sidebar.write(f"–¢–∏–ø –º–æ–¥–µ–ª–∏: {type(model).__name__}")
    
    if 'error' not in metadata:
        st.sidebar.write("–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
        for key, value in metadata.items():
            if key != 'error':
                st.sidebar.write(f"- {key}: {value}")

if __name__ == "__main__":
    main()