from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.calibration import CalibratedClassifierCV
import numpy as np
import joblib
import warnings
import seaborn as sns
import matplotlib.pyplot as plt
from typing import List, Dict, Any, Optional, Tuple
from collections import Counter
import pandas as pd

warnings.filterwarnings('ignore')

from util.jsonl_process import read_jsonl_basic


class VotingCategoryClassifier:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è (Voting) –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    """

    def __init__(self,
                 voting_type: str = 'soft',
                 class_names: Optional[List[str]] = None,
                 text_field: str = 'text',
                 label_field: str = 'category',
                 random_state: int = 42):
        """
        Args:
            voting_type: 'hard' –∏–ª–∏ 'soft' –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ
            class_names: —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            text_field: –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è —Å —Ç–µ–∫—Å—Ç–æ–º
            label_field: –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è —Å –º–µ—Ç–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            random_state: –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        """
        self.vectorizer = TfidfVectorizer(
            max_features=10000,
            min_df=2,
            max_df=0.9,
            ngram_range=(1, 2),
            stop_words=None
        )

        # –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è
        self.models = {
            'logistic': LogisticRegression(
                C=1.0,
                random_state=random_state,
                max_iter=1000,
                multi_class='multinomial',
                solver='lbfgs'
            ),
            'svm_linear': SVC(
                C=1.0,
                kernel='linear',
                probability=True,  # –î–ª—è soft voting
                random_state=random_state,
                decision_function_shape='ovr'
            ),
            'random_forest': RandomForestClassifier(
                n_estimators=100,
                max_depth=None,
                random_state=random_state,
                n_jobs=-1
            ),
            'svm_rbf': SVC(
                C=1.0,
                kernel='rbf',
                probability=True,
                random_state=random_state,
                decision_function_shape='ovr'
            ),
            'logistic_l2': LogisticRegression(
                C=0.1,
                penalty='l2',
                random_state=random_state,
                max_iter=1000,
                multi_class='multinomial',
                solver='lbfgs'
            )
        }

        self.voting_classifier = VotingClassifier(
            estimators=[(name, model) for name, model in self.models.items()],
            voting=voting_type,
            n_jobs=-1,
            verbose=0
        )

        self.label_encoder = LabelEncoder()
        self.class_names = class_names
        self.voting_type = voting_type
        self.text_field = text_field
        self.label_field = label_field
        self.is_trained = False
        self.num_classes = 0
        self.random_state = random_state

    def prepare_data(self, data: List[Dict[str, Any]]) -> Tuple[List[str], List[str]]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö: –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏ –º–µ—Ç–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        """
        texts = [item[self.text_field] for item in data]
        labels = [item[self.label_field] for item in data]
        return texts, labels

    def analyze_class_distribution(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö
        """
        _, labels = self.prepare_data(data)
        label_counts = Counter(labels)

        result = {
            'total_samples': len(data),
            'num_classes': len(label_counts),
            'classes': dict(label_counts),
            'class_percentages': {},
            'imbalance_ratio': None,
            'unique_labels': sorted(list(label_counts.keys()))
        }

        if label_counts:
            max_count = max(label_counts.values())
            min_count = min(label_counts.values())
            if min_count > 0:
                result['imbalance_ratio'] = max_count / min_count

            for label, count in label_counts.items():
                result['class_percentages'][label] = count / len(data) * 100

        return result

    def train(self, train_data: List[Dict[str, Any]],
              val_data: Optional[List[Dict[str, Any]]] = None) -> None:
        """
        –û–±—É—á–µ–Ω–∏–µ voting –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        """
        print(f"üéØ –û–ë–£–ß–ï–ù–ò–ï {self.voting_type.upper()} VOTING –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê...")
        print(f"   –ü–æ–ª–µ —Å —Ç–µ–∫—Å—Ç–æ–º: '{self.text_field}'")
        print(f"   –ü–æ–ª–µ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π: '{self.label_field}'")

        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        train_dist = self.analyze_class_distribution(train_data)
        print(f"\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ô –í TRAIN:")
        print(f"   –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {train_dist['total_samples']}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {train_dist['num_classes']}")

        if train_dist['imbalance_ratio']:
            print(f"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞: {train_dist['imbalance_ratio']:.2f}")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X_train, y_train_raw = self.prepare_data(train_data)

        # –ö–æ–¥–∏—Ä—É–µ–º –º–µ—Ç–∫–∏
        if self.class_names is None:
            self.label_encoder.fit(y_train_raw)
            self.class_names = list(self.label_encoder.classes_)
        else:
            self.label_encoder.fit(self.class_names)

        y_train = self.label_encoder.transform(y_train_raw)
        self.num_classes = len(self.class_names)

        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
        print(f"\nüìã –°–ü–ò–°–û–ö –ö–ê–¢–ï–ì–û–†–ò–ô ({self.num_classes}):")
        for i, (class_name, count) in enumerate(train_dist['classes'].items()):
            percentage = train_dist['class_percentages'].get(class_name, 0)
            print(f"   {i + 1:2d}. {class_name}: {count} –ø—Ä–∏–º–µ—Ä–æ–≤ ({percentage:.1f}%)")

        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤
        print("\nüìä –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤...")
        X_train_vec = self.vectorizer.fit_transform(X_train)

        print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train_vec.shape}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤/—Ñ—Ä–∞–∑: {len(self.vectorizer.get_feature_names_out())}")
        print(f"   –¢–∏–ø –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è: {self.voting_type}")
        print(f"   –ú–æ–¥–µ–ª–∏ –≤ –∞–Ω—Å–∞–º–±–ª–µ: {list(self.models.keys())}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π: {len(self.models)}")

        # –û–±—É—á–µ–Ω–∏–µ voting –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        print("\nü§ñ –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è...")
        self.voting_classifier.fit(X_train_vec, y_train)
        self.is_trained = True

        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        train_pred = self.voting_classifier.predict(X_train_vec)
        train_accuracy = accuracy_score(y_train, train_pred)
        print(f"\n‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ train: {train_accuracy:.3f}")

        # –û—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º –Ω–∞ train
        print("\nüìä –û–¢–ß–ï–¢ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú (train):")
        print(classification_report(y_train, train_pred, target_names=self.class_names))

        # –û—Ü–µ–Ω–∫–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        individual_accuracies = self._evaluate_individual_models(X_train_vec, y_train)

        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
        if val_data:
            val_accuracy, _ = self.evaluate(val_data, detailed=False)
            print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ val: {val_accuracy:.3f}")

        # –ê–Ω–∞–ª–∏–∑ –∞–Ω—Å–∞–º–±–ª—è
        self._analyze_ensemble(X_train_vec, y_train, individual_accuracies)

        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –Ω–∞ train
        if self.num_classes > 1 and self.num_classes <= 15:
            self._plot_confusion_matrix(y_train, train_pred, "Train Confusion Matrix")

    def _evaluate_individual_models(self, X_vec, y_true) -> Dict[str, float]:
        """
        –û—Ü–µ–Ω–∫–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        """
        print(f"\nüìä –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–´–• –ú–û–î–ï–õ–ï–ô:")
        print("-" * 50)

        individual_accuracies = {}

        for name, model in self.models.items():
            try:
                # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –æ—Ç–¥–µ–ª—å–Ω–æ –µ—Å–ª–∏ –æ–Ω–∞ –µ—â–µ –Ω–µ –æ–±—É—á–µ–Ω–∞
                # (–≤ VotingClassifier –º–æ–¥–µ–ª–∏ —É–∂–µ –æ–±—É—á–µ–Ω—ã, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
                if not hasattr(model, 'classes_'):
                    model.fit(X_vec, y_true)

                pred = model.predict(X_vec)
                accuracy = accuracy_score(y_true, pred)
                individual_accuracies[name] = accuracy
                print(f"   {name:<15}: {accuracy:.3f}")

            except Exception as e:
                print(f"   {name:<15}: –æ—à–∏–±–∫–∞ - {e}")
                individual_accuracies[name] = 0

        return individual_accuracies

    def _analyze_ensemble(self, X_vec, y_true, individual_accuracies: Dict[str, float]):
        """
        –ê–Ω–∞–ª–∏–∑ —Ä–∞–±–æ—Ç—ã –∞–Ω—Å–∞–º–±–ª—è
        """
        print(f"\nüìä –ê–ù–ê–õ–ò–ó {self.voting_type.upper()} VOTING –ê–ù–°–ê–ú–ë–õ–Ø:")
        print("-" * 50)

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        all_predictions = {}
        for name, model in self.models.items():
            if hasattr(model, 'predict'):
                try:
                    all_predictions[name] = model.predict(X_vec)
                except:
                    continue

        # –ê–Ω–∞–ª–∏–∑ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
        n_samples = len(y_true)
        n_models = len(all_predictions)

        if n_models > 0:
            # –°—á–∏—Ç–∞–µ–º –µ–¥–∏–Ω–æ–≥–ª–∞—Å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
            unanimous_count = 0
            for i in range(n_samples):
                votes = [pred[i] for pred in all_predictions.values()]
                unique_votes = set(votes)
                if len(unique_votes) == 1:
                    unanimous_count += 1

            # –°—á–∏—Ç–∞–µ–º —Å–æ–≥–ª–∞—Å–∏–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞
            majority_agree_count = 0
            for i in range(n_samples):
                votes = [pred[i] for pred in all_predictions.values()]
                from collections import Counter
                vote_counts = Counter(votes)
                majority_vote = max(vote_counts.values())
                if majority_vote >= n_models * 0.5:  # –ë–æ–ª–µ–µ 50%
                    majority_agree_count += 1

            print(f"   –ï–¥–∏–Ω–æ–≥–ª–∞—Å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è: {unanimous_count}/{n_samples} ({unanimous_count / n_samples * 100:.1f}%)")
            print(
                f"   –°–æ–≥–ª–∞—Å–∏–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞: {majority_agree_count}/{n_samples} ({majority_agree_count / n_samples * 100:.1f}%)")

        # –¢–æ—á–Ω–æ—Å—Ç—å –∞–Ω—Å–∞–º–±–ª—è
        ensemble_pred = self.voting_classifier.predict(X_vec)
        ensemble_accuracy = accuracy_score(y_true, ensemble_pred)
        print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –∞–Ω—Å–∞–º–±–ª—è: {ensemble_accuracy:.3f}")

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ª—É—á—à–µ–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é
        if individual_accuracies:
            best_model_name = max(individual_accuracies, key=individual_accuracies.get)
            best_model_accuracy = individual_accuracies[best_model_name]
            improvement = ensemble_accuracy - best_model_accuracy

            print(f"   –õ—É—á—à–∞—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å: {best_model_name} ({best_model_accuracy:.3f})")
            print(f"   –£–ª—É—á—à–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è: {improvement:+.3f}")
            if best_model_accuracy > 0:
                print(f"   –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {improvement / best_model_accuracy * 100:+.1f}%")

    def predict(self, texts: List[str]) -> Tuple[List[str], np.ndarray]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤
        """
        if not self.is_trained:
            raise Exception("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")

        X_vec = self.vectorizer.transform(texts)
        predictions_encoded = self.voting_classifier.predict(X_vec)

        # –î–ª—è soft voting –ø–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –¥–ª—è hard voting - –≤—ã—á–∏—Å–ª—è–µ–º
        if self.voting_type == 'soft':
            probabilities = self.voting_classifier.predict_proba(X_vec)
        else:
            probabilities = self._get_hard_voting_probabilities(X_vec)

        predictions = self.label_encoder.inverse_transform(predictions_encoded)
        return predictions, probabilities

    def _get_hard_voting_probabilities(self, X_vec) -> np.ndarray:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –ø—Å–µ–≤–¥–æ-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è hard voting
        """
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        all_predictions = []
        for name, model in self.models.items():
            if hasattr(model, 'predict'):
                try:
                    pred = model.predict(X_vec)
                    all_predictions.append(pred)
                except:
                    continue

        if not all_predictions:
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π")

        all_predictions = np.array(all_predictions)
        n_models = len(all_predictions)
        n_samples = len(all_predictions[0])

        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        probabilities = np.zeros((n_samples, self.num_classes))

        for i in range(n_samples):
            votes = all_predictions[:, i]
            for class_idx in range(self.num_classes):
                class_votes = np.sum(votes == class_idx)
                probabilities[i, class_idx] = class_votes / n_models

        return probabilities

    def predict_single(self, text: str) -> Dict[str, Any]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        predictions, probabilities = self.predict([text])
        pred = predictions[0]
        pred_encoded = self.label_encoder.transform([pred])[0]
        prob = probabilities[0]

        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        class_probs = {}
        for i, cls in enumerate(self.class_names):
            class_probs[cls] = prob[i]

        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ–ø-3 –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        top_n = min(3, self.num_classes)
        top_indices = np.argsort(prob)[-top_n:][::-1]
        top_categories = []
        for idx in top_indices:
            top_categories.append({
                'category': self.class_names[idx],
                'probability': prob[idx],
                'probability_percent': prob[idx] * 100
            })

        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–∏
        voting_details = self._get_voting_details(text)

        return {
            'prediction': pred,
            'category': pred,
            'prediction_encoded': pred_encoded,
            'category_probabilities': class_probs,
            'top_categories': top_categories,
            'confidence': prob[pred_encoded],
            'confidence_percent': prob[pred_encoded] * 100,
            'voting_type': self.voting_type,
            'voting_details': voting_details
        }

    def _get_voting_details(self, text: str) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π
        """
        X_vec = self.vectorizer.transform([text])

        voting_results = {}
        all_predictions = []
        all_probabilities = []

        for name, model in self.models.items():
            try:
                pred_encoded = model.predict(X_vec)[0]
                pred = self.label_encoder.inverse_transform([pred_encoded])[0]

                if hasattr(model, 'predict_proba'):
                    prob = model.predict_proba(X_vec)[0]
                else:
                    # –î–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å–æ–∑–¥–∞–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                    prob = np.ones(self.num_classes) / self.num_classes

                voting_results[name] = {
                    'prediction': pred,
                    'prediction_encoded': pred_encoded,
                    'probability': prob,
                    'top_category': self.class_names[np.argmax(prob)],
                    'top_probability': np.max(prob),
                    'confidence': np.max(prob)
                }

                all_predictions.append(pred_encoded)
                all_probabilities.append(prob)

            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ –º–æ–¥–µ–ª–∏ {name}: {e}")
                continue

        # –ê–Ω–∞–ª–∏–∑ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è
        if all_predictions:
            # –ü–æ–¥—Å—á–µ—Ç –≥–æ–ª–æ—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            vote_counts = {}
            for pred_encoded in all_predictions:
                pred = self.label_encoder.inverse_transform([pred_encoded])[0]
                vote_counts[pred] = vote_counts.get(pred, 0) + 1

            total_votes = len(all_predictions)
            max_votes = max(vote_counts.values()) if vote_counts else 0
            winning_category = max(vote_counts, key=vote_counts.get) if vote_counts else None

            if self.voting_type == 'soft':
                # –î–ª—è soft voting –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                avg_probabilities = np.mean(all_probabilities, axis=0)
                winning_idx = np.argmax(avg_probabilities)
                decision_reason = f"Soft voting (—Å—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {avg_probabilities[winning_idx]:.3f})"
            else:
                decision_reason = f"Hard voting ({max_votes}/{total_votes} –∑–∞ {winning_category})"

            return {
                'individual_votes': voting_results,
                'vote_counts': vote_counts,
                'total_votes': total_votes,
                'winning_category': winning_category,
                'max_votes': max_votes,
                'consensus_ratio': max_votes / total_votes if total_votes > 0 else 0,
                'unanimous': len(set(all_predictions)) == 1 if all_predictions else False,
                'decision_reason': decision_reason
            }
        else:
            return {
                'individual_votes': {},
                'vote_counts': {},
                'total_votes': 0,
                'winning_category': None,
                'max_votes': 0,
                'consensus_ratio': 0,
                'unanimous': False,
                'decision_reason': '–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π'
            }

    def evaluate(self, test_data: List[Dict[str, Any]],
                 detailed: bool = True,
                 plot_confusion_matrix: bool = True) -> Tuple[float, Dict]:
        """
        –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        """
        X_test, y_test_raw = self.prepare_data(test_data)

        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
        y_test = []
        for label in y_test_raw:
            if label in self.label_encoder.classes_:
                y_test.append(label)
            else:
                y_test.append(self.class_names[0])

        y_test_encoded = self.label_encoder.transform(y_test)
        X_test_vec = self.vectorizer.transform(X_test)

        y_pred_encoded = self.voting_classifier.predict(X_test_vec)
        y_pred = self.label_encoder.inverse_transform(y_pred_encoded)
        accuracy = accuracy_score(y_test_encoded, y_pred_encoded)

        if detailed:
            print(f"\nüìä –û–¶–ï–ù–ö–ê –ù–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–•:")
            print(f"   –ü—Ä–∏–º–µ—Ä–æ–≤: {len(test_data)}")
            print(f"   –¢–∏–ø –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è: {self.voting_type}")
            print(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.3f}")

            print(f"\nüìà –î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
            print(classification_report(y_test_encoded, y_pred_encoded,
                                        target_names=self.class_names, digits=3))

            # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
            if self.num_classes > 1 and self.num_classes <= 15:
                print(f"\nüìä –ú–ê–¢–†–ò–¶–ê –û–®–ò–ë–û–ö:")
                cm = confusion_matrix(y_test_encoded, y_pred_encoded)
                self._print_confusion_matrix(cm)

                if plot_confusion_matrix:
                    self._plot_confusion_matrix(y_test_encoded, y_pred_encoded,
                                                f"Test Confusion Matrix ({self.voting_type} Voting)")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        report_dict = classification_report(y_test_encoded, y_pred_encoded,
                                            target_names=self.class_names,
                                            output_dict=True)

        return accuracy, report_dict

    def _print_confusion_matrix(self, cm: np.ndarray) -> None:
        """
        –ö—Ä–∞—Å–∏–≤–æ –ø–µ—á–∞—Ç–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫
        """
        n_classes = len(self.class_names)

        if n_classes <= 1:
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫")
            return

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        max_class_len = max(len(cls) for cls in self.class_names)
        header_padding = max(12, max_class_len + 2)

        header = " " * header_padding + " | "
        header += " ".join([f"{cls[:10]:>10}" for cls in self.class_names])
        print(header)
        print("-" * (header_padding + 3 + n_classes * 11))

        # –°—Ç—Ä–æ–∫–∏
        for i, cls in enumerate(self.class_names):
            row = f"{cls[:header_padding - 2]:>{header_padding - 2}} | "
            row += " ".join([f"{cm[i][j]:>10}" for j in range(n_classes)])
            print(row)

    def _plot_confusion_matrix(self, y_true: np.ndarray,
                               y_pred: np.ndarray,
                               title: str = "Confusion Matrix") -> None:
        """
        –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
        """
        try:
            if self.num_classes <= 1 or self.num_classes > 15:
                return

            cm = confusion_matrix(y_true, y_pred)

            plt.figure(figsize=(max(10, min(self.num_classes, 12)),
                                max(8, min(self.num_classes * 0.8, 10))))

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º (–ø–æ –∏—Å—Ç–∏–Ω–Ω—ã–º –º–µ—Ç–∫–∞–º)
            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
            cm_normalized = np.nan_to_num(cm_normalized)  # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ 0

            sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',
                        xticklabels=self.class_names,
                        yticklabels=self.class_names,
                        vmin=0, vmax=1)
            plt.title(f"{title} (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–∞)")
            plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
            plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
            plt.tight_layout()

            filename = title.lower().replace(' ', '_').replace('(', '').replace(')', '').replace(' ', '_')
            plt.savefig(f"{filename}.png", dpi=300, bbox_inches='tight')
            plt.show()
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫: {e}")

    def compare_with_individual_models(self, test_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        """
        X_test, y_test_raw = self.prepare_data(test_data)

        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
        y_test = []
        for label in y_test_raw:
            if label in self.label_encoder.classes_:
                y_test.append(label)
            else:
                y_test.append(self.class_names[0])

        y_test_encoded = self.label_encoder.transform(y_test)
        X_test_vec = self.vectorizer.transform(X_test)

        print(f"\nüî¨ –°–†–ê–í–ù–ï–ù–ò–ï {self.voting_type.upper()} VOTING –° –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–´–ú–ò –ú–û–î–ï–õ–Ø–ú–ò:")
        print("=" * 60)

        # –¢–æ—á–Ω–æ—Å—Ç—å –∞–Ω—Å–∞–º–±–ª—è
        ensemble_pred_encoded = self.voting_classifier.predict(X_test_vec)
        ensemble_accuracy = accuracy_score(y_test_encoded, ensemble_pred_encoded)
        print(f"   {'VOTING ENSEMBLE':<20}: {ensemble_accuracy:.3f}")

        # –¢–æ—á–Ω–æ—Å—Ç–∏ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        individual_accuracies = {}
        for name, model in self.models.items():
            try:
                pred_encoded = model.predict(X_test_vec)
                accuracy = accuracy_score(y_test_encoded, pred_encoded)
                individual_accuracies[name] = accuracy
                print(f"   {name:<20}: {accuracy:.3f}")
            except Exception as e:
                print(f"   {name:<20}: –æ—à–∏–±–∫–∞ - {e}")

        # –ê–Ω–∞–ª–∏–∑ —É–ª—É—á—à–µ–Ω–∏—è
        comparison_result = {}
        if individual_accuracies:
            best_individual_name = max(individual_accuracies, key=individual_accuracies.get)
            best_individual_accuracy = individual_accuracies[best_individual_name]
            improvement = ensemble_accuracy - best_individual_accuracy

            print(f"\n   üìà –£–ª—É—á—à–µ–Ω–∏–µ –Ω–∞–¥ –ª—É—á—à–µ–π –º–æ–¥–µ–ª—å—é ({best_individual_name}): {improvement:.3f}")
            if best_individual_accuracy > 0:
                print(f"   üìà –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {improvement / best_individual_accuracy * 100:.1f}%")

            comparison_result = {
                'ensemble_accuracy': ensemble_accuracy,
                'individual_accuracies': individual_accuracies,
                'improvement': improvement,
                'best_individual_name': best_individual_name,
                'best_individual_accuracy': best_individual_accuracy
            }

        return comparison_result

    def save_model(self, filename: str) -> None:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        """
        joblib.dump({
            'voting_classifier': self.voting_classifier,
            'vectorizer': self.vectorizer,
            'label_encoder': self.label_encoder,
            'class_names': self.class_names,
            'models': self.models,
            'voting_type': self.voting_type,
            'text_field': self.text_field,
            'label_field': self.label_field,
            'num_classes': self.num_classes,
            'random_state': self.random_state
        }, filename)
        print(f"üíæ Voting –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filename}")

    def load_model(self, filename: str) -> None:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        """
        loaded = joblib.load(filename)
        self.voting_classifier = loaded['voting_classifier']
        self.vectorizer = loaded['vectorizer']
        self.label_encoder = loaded['label_encoder']
        self.class_names = loaded['class_names']
        self.models = loaded['models']
        self.voting_type = loaded['voting_type']
        self.text_field = loaded.get('text_field', 'text')
        self.label_field = loaded.get('label_field', 'category')
        self.num_classes = loaded.get('num_classes', len(self.class_names))
        self.random_state = loaded.get('random_state', 42)
        self.is_trained = True

        print(f"üì• Voting –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {filename}")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {self.class_names}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {self.num_classes}")
        print(f"   –¢–∏–ø –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è: {self.voting_type}")


def compare_voting_strategies(train_data: List[Dict[str, Any]],
                              val_data: List[Dict[str, Any]],
                              test_data: List[Dict[str, Any]],
                              text_field: str = 'text',
                              label_field: str = 'category') -> Dict[str, Any]:
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Hard Voting –∏ Soft Voting
    """
    print("üî¨ –°–†–ê–í–ù–ï–ù–ò–ï HARD VS SOFT VOTING")
    print("=" * 60)

    results = {}

    for voting_type in ['hard', 'soft']:
        print(f"\nüéØ {voting_type.upper()} VOTING:")
        voting_classifier = VotingCategoryClassifier(
            voting_type=voting_type,
            text_field=text_field,
            label_field=label_field
        )

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ
        if len(train_data) > 500:
            train_subset = train_data[:500]
            print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –∏–∑ {len(train_subset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
        else:
            train_subset = train_data

        voting_classifier.train(train_subset, val_data)

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        comparison = voting_classifier.compare_with_individual_models(test_data)

        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ
        test_accuracy, _ = voting_classifier.evaluate(test_data, detailed=False)

        results[voting_type] = {
            'classifier': voting_classifier,
            'comparison': comparison,
            'test_accuracy': test_accuracy
        }

    # –ò—Ç–æ–≥–æ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    print("\nüìä –ò–¢–û–ì–û–í–û–ï –°–†–ê–í–ù–ï–ù–ò–ï:")
    print("=" * 40)

    for voting_type, result in results.items():
        accuracy = result['test_accuracy']
        improvement = result['comparison'].get('improvement', 0) if result['comparison'] else 0
        print(f"   {voting_type.upper():<12} Voting: {accuracy:.3f} (—É–ª—É—á—à–µ–Ω–∏–µ: {improvement:+.3f})")

    return results


def quick_train_voting(train_file: str,
                       val_file: Optional[str] = None,
                       test_file: Optional[str] = None,
                       text_field: str = 'text',
                       label_field: str = 'category',
                       voting_type: str = 'soft',
                       output_model: str = 'voting_category_classifier.pkl') -> Optional[VotingCategoryClassifier]:
    """
    –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ Voting –º–æ–¥–µ–ª–∏ –∏–∑ —Ñ–∞–π–ª–æ–≤
    """
    import json
    import os

    def load_jsonl(filepath: str) -> List[Dict[str, Any]]:
        if not os.path.exists(filepath):
            print(f"‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
            return []
        with open(filepath, 'r', encoding='utf-8') as f:
            return [json.loads(line) for line in f]

    print("üöÄ –ó–ê–ü–£–°–ö –ë–´–°–¢–†–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø VOTING –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê")
    print("=" * 60)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    train_data = load_jsonl(train_file)
    if not train_data:
        print(f"‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ {train_file}")
        return None

    print(f"   Train: {len(train_data)} –ø—Ä–∏–º–µ—Ä–æ–≤")

    if val_file:
        val_data = load_jsonl(val_file)
        print(f"   Val: {len(val_data)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    else:
        val_data = None

    if test_file:
        test_data = load_jsonl(test_file)
        print(f"   Test: {len(test_data)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    else:
        test_data = None

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
    if train_data:
        sample_item = train_data[0]
        if text_field not in sample_item:
            print(f"‚ùå –û—à–∏–±–∫–∞: –ø–æ–ª–µ '{text_field}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–∞–Ω–Ω—ã—Ö")
            return None
        if label_field not in sample_item:
            print(f"‚ùå –û—à–∏–±–∫–∞: –ø–æ–ª–µ '{label_field}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–∞–Ω–Ω—ã—Ö")
            return None

    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    print(f"\nüéØ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è Voting –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
    print(f"   –¢–∏–ø –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è: {voting_type}")

    classifier = VotingCategoryClassifier(
        voting_type=voting_type,
        text_field=text_field,
        label_field=label_field
    )

    classifier.train(train_data, val_data)

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º, –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    if test_data:
        print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        accuracy, report = classifier.evaluate(test_data, detailed=True)
        print(f"\nüéØ –ò—Ç–æ–≥–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {accuracy:.3f}")

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        comparison = classifier.compare_with_individual_models(test_data)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        if report:
            report_df = pd.DataFrame(report).transpose()
            report_df.to_csv('voting_classification_report.csv', index=True)
            print(f"üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ 'voting_classification_report.csv'")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    classifier.save_model(output_model)

    # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä
    print(f"\nüß™ –¢–ï–°–¢–û–í–´–ô –ü–†–ò–ú–ï–† –†–ê–ë–û–¢–´ –ú–û–î–ï–õ–ò:")
    if train_data:
        sample_text = train_data[0][text_field]
        if len(sample_text) > 100:
            sample_text = sample_text[:100] + "..."
        result = classifier.predict_single(sample_text)
        print(f"   –¢–µ–∫—Å—Ç: '{sample_text}'")
        print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {result['prediction']}")
        print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence_percent']:.1f}%")
        print(f"   –¢–∏–ø –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è: {result['voting_type']}")

        if result['top_categories']:
            print(f"   –¢–æ–ø-3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:")
            for i, cat in enumerate(result['top_categories'], 1):
                print(f"     {i}. {cat['category']}: {cat['probability_percent']:.1f}%")

        if result['voting_details']:
            print(f"   –î–µ—Ç–∞–ª–∏ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è:")
            for model_name, vote in result['voting_details']['individual_votes'].items():
                print(f"     {model_name}: {vote['prediction']} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {vote['confidence']:.3f})")

    return classifier


def main():
    """
    –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Voting –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    """
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        train_data = read_jsonl_basic('../util/news_category_train.jsonl')
        val_data = read_jsonl_basic('../util/news_category_val.jsonl')
        test_data = read_jsonl_basic('../util/news_category_test.jsonl')

        print(f"üìä –î–∞–Ω–Ω—ã–µ: {len(train_data)} train, {len(val_data)} val, {len(test_data)} test")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
        if train_data:
            print(f"\nüìã –ü–†–ò–ú–ï–† –î–ê–ù–ù–´–•:")
            sample = train_data[0]
            print(f"   –ü–æ–ª—è: {list(sample.keys())}")
            print(f"   –¢–µ–∫—Å—Ç: {sample.get('text', 'N/A')[:100]}...")
            print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {sample.get('category', 'N/A')}")

        # 1. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Soft Voting
        print("\n" + "=" * 60)
        print("üéØ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï SOFT VOTING")

        soft_voting = VotingCategoryClassifier(voting_type='soft')

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –º–Ω–æ–≥–æ
        if len(train_data) > 500:
            train_subset = train_data[:500]
            print(f"‚ÑπÔ∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –∏–∑ {len(train_subset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
        else:
            train_subset = train_data

        soft_voting.train(train_subset, val_data)

        # 2. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Hard Voting
        print("\n" + "=" * 60)
        print("üéØ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï HARD VOTING")

        hard_voting = VotingCategoryClassifier(voting_type='hard')
        hard_voting.train(train_subset, val_data)

        # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        print("\n" + "=" * 60)
        results = compare_voting_strategies(train_data, val_data, test_data, 'text', 'category')

        # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        soft_voting.save_model("soft_voting_category_classifier.pkl")
        hard_voting.save_model("hard_voting_category_classifier.pkl")

    except FileNotFoundError as e:
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
        print("‚ÑπÔ∏è  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω—ã—Ö")
    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–∞
    print("üöÄ –ó–ê–ü–£–°–ö –ü–†–ò–ú–ï–†–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø VOTING –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–†–ê")
    print("=" * 60)
    main()