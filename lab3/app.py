import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import joblib
import pickle
import json
import os
import warnings

warnings.filterwarnings('ignore')
from pathlib import Path
from wordcloud import WordCloud
import shap
import lime
import lime.lime_text
from sklearn.feature_extraction.text import TfidfVectorizer
import base64
from io import BytesIO
import hashlib

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="Analyzer: NLP Classifiers",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS —Å—Ç–∏–ª–∏
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.8rem;
        color: #3B82F6;
        margin-top: 1.5rem;
        margin-bottom: 1rem;
    }
    .model-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        color: white;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .metric-box {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 10px;
        margin: 5px 0;
        border-left: 4px solid #3B82F6;
    }
    .stButton>button {
        background: linear-gradient(45deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        padding: 10px 20px;
        border-radius: 5px;
        font-weight: bold;
    }
    .success-box {
        background-color: #d1fae5;
        padding: 15px;
        border-radius: 8px;
        border-left: 5px solid #10b981;
        margin: 10px 0;
    }
    .error-box {
        background-color: #fee2e2;
        padding: 15px;
        border-radius: 8px;
        border-left: 5px solid #ef4444;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)


def generate_key(*args):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫–ª—é—á–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤"""
    key_string = "_".join(str(arg) for arg in args)
    return hashlib.md5(key_string.encode()).hexdigest()[:10]


class ModelLoader:
    def __init__(self):
        self.models_cache = {}

    def load_models(self, task_type):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏"""
        if task_type in self.models_cache:
            return self.models_cache[task_type]

        models = {}

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
        model_paths = {
            "binary": [
                "bagging_sentiment_classifier.pkl",
                "binary_sentiment_classifier.pkl",
                "blending_classifier.pkl",
                "catboost_sentiment_classifier.cbm",
                "catboost_sentiment_classifier.pkl",
                "h2o_sentiment_model_meta.pkl",
                "hard_voting_classifier.pkl",
                "random_forest_sentiment_classifier.pkl",
                "simple_automl_classifier.pkl",
                "simple_classifier.pkl",
                "soft_voting_classifier.pkl",
                "stacking_classifier.pkl",
                "svm_sentiment_classifier.pkl"
            ],
            "multiclass": [
                "blending_category_classifier.pkl",
                "bagging_multiclass_model.pkl",
                "catboost_multiclass_model.cbm",
                "catboost_multiclass_model.pkl",
                "h2o_multiclass_model_meta.pkl",
                "hard_voting_category_classifier.pkl",
                "multiclass_automl_model.pkl",
                "multiclass_category_classifier.pkl",
                "simple_category_classifier.pkl",
                "soft_voting_category_classifier.pkl",
                "stacking_category_classifier.pkl",
                "svm_category_classifier.pkl",
                "tpot_category_classifier.pkl"
            ],
            "multilabel": [
                "multilabel_automl_classifier.pkl",
                "multilabel_bagging.pkl",
                "multilabel_blending.pkl",
                "multilabel_catboost.pkl",
                "multilabel_classifier.pkl",
                "multilabel_random_forest.pkl",
                "multilabel_random_search.pkl",
                "multilabel_svm_classifier.pkl",
                "multilabel_voting_soft.pkl"
            ]
        }

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        for model_name in model_paths.get(task_type, []):
            clean_name = model_name.replace('.pkl', '').replace('.cbm', '')
            models[clean_name] = {
                "type": "dummy",
                "name": model_name,
                "accuracy": np.random.uniform(0.6, 0.95),
                "f1_score": np.random.uniform(0.5, 0.9)
            }

        self.models_cache[task_type] = models
        return models

    def predict(self, model_info, text, task_type):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—Ñ–∏–∫—Ç–∏–≤–Ω–æ–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)"""
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            np.random.seed(hash(text) % 10000)

            if task_type == "binary":
                prob = np.random.uniform(0, 1)
                prediction = "Positive" if prob > 0.5 else "Negative"
                return {
                    'prediction': prediction,
                    'probability': float(prob),
                    'labels': ['Negative', 'Positive'],
                    'probabilities': [float(1 - prob), float(prob)]
                }

            elif task_type == "multiclass":
                classes = ["Technology", "Sports", "Politics", "Economy", "Culture"]
                probs = np.random.dirichlet(np.ones(len(classes)))
                prediction = classes[np.argmax(probs)]
                return {
                    'prediction': prediction,
                    'probabilities': probs.tolist(),
                    'labels': classes
                }

            elif task_type == "multilabel":
                labels = ["Technology", "Sports", "Politics", "Economy", "Culture", "Science", "Health"]
                probs = np.random.uniform(0, 1, len(labels))
                predictions = [labels[i] for i in range(len(labels)) if probs[i] > 0.5]
                return {
                    'predictions': predictions,
                    'probabilities': probs.tolist(),
                    'labels': labels
                }

        except Exception as e:
            return {'error': str(e)}


class VisualizationManager:
    def __init__(self):
        plt.style.use('seaborn-v0_8-darkgrid')
        self.colors = px.colors.qualitative.Set3

    def plot_word_cloud(self, text, title="Word Cloud"):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤"""
        fig, ax = plt.subplots(figsize=(10, 6))
        wordcloud = WordCloud(
            width=800,
            height=400,
            background_color='white',
            colormap='viridis'
        ).generate(text)

        ax.imshow(wordcloud, interpolation='bilinear')
        ax.set_title(title, fontsize=16)
        ax.axis('off')
        return fig

    def plot_confusion_matrix(self, cm, labels, title="Confusion Matrix"):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫"""
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(
            cm,
            annot=True,
            fmt='d',
            cmap='Blues',
            xticklabels=labels,
            yticklabels=labels,
            ax=ax
        )
        ax.set_xlabel('Predicted')
        ax.set_ylabel('Actual')
        ax.set_title(title)
        return fig


class ClassifierAnalyzerApp:
    def __init__(self):
        self.model_loader = ModelLoader()
        self.viz_manager = VisualizationManager()
        self.initialize_session_state()
        self.plot_counter = 0  # –°—á–µ—Ç—á–∏–∫ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π

    def get_unique_key(self, prefix="plot"):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫–ª—é—á–∞"""
        self.plot_counter += 1
        return f"{prefix}_{self.plot_counter}"

    def initialize_session_state(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏"""
        default_states = {
            'current_text': "",
            'current_task': "binary",
            'selected_models': [],
            'predictions': {},
            'explanations': {},
            'show_details': False
        }

        for key, value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = value

    def get_example_texts(self, task_type):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤"""
        examples = {
            "binary": {
                "–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–∑—ã–≤": "–≠—Ç–æ—Ç –ø—Ä–æ–¥—É–∫—Ç –ø—Ä–µ–≤–∑–æ—à–µ–ª –≤—Å–µ –º–æ–∏ –æ–∂–∏–¥–∞–Ω–∏—è! –û—á–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∏ —É–¥–æ–±–Ω—ã–π –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏. –†–µ–∫–æ–º–µ–Ω–¥—É—é –≤—Å–µ–º!",
                "–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–∑—ã–≤": "–£–∂–∞—Å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, —Å–ª–æ–º–∞–ª—Å—è —á–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é. –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –ø–æ–∫—É–ø–∞—Ç—å —ç—Ç–æ—Ç —Ç–æ–≤–∞—Ä. –î–µ–Ω—å–≥–∏ –Ω–∞ –≤–µ—Ç–µ—Ä.",
                "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –æ—Ç–∑—ã–≤": "–¢–æ–≤–∞—Ä —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é, –Ω–æ –Ω–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ. –ó–∞ —Å–≤–æ—é —Ü–µ–Ω—É –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–æ –Ω–µ –±–æ–ª–µ–µ —Ç–æ–≥–æ."
            },
            "multiclass": {
                "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": "–ù–æ–≤–µ–π—à–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —Ä–µ–∫–æ—Ä–¥–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –∏–≥—Ä–∞—Ö –∏ —Ç—è–∂–µ–ª—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö.",
                "–°–ø–æ—Ä—Ç": "–§—É—Ç–±–æ–ª—å–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –≤—ã–∏–≥—Ä–∞–ª–∞ —á–µ–º–ø–∏–æ–Ω–∞—Ç –≤ –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω–æ–π –±–æ—Ä—å–±–µ —Å —Å–∏–ª—å–Ω—ã–º —Å–æ–ø–µ—Ä–Ω–∏–∫–æ–º.",
                "–ü–æ–ª–∏—Ç–∏–∫–∞": "–ü–∞—Ä–ª–∞–º–µ–Ω—Ç –ø—Ä–∏–Ω—è–ª –Ω–æ–≤—ã–π –∑–∞–∫–æ–Ω –æ —Ü–∏—Ñ—Ä–æ–≤–æ–π —ç–∫–æ–Ω–æ–º–∏–∫–µ –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏—è—Ö.",
                "–≠–∫–æ–Ω–æ–º–∏–∫–∞": "–ë–∏—Ä–∂–µ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —É—Å—Ç–æ–π—á–∏–≤—ã–π —Ä–æ—Å—Ç –Ω–∞ —Ñ–æ–Ω–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏."
            },
            "multilabel": {
                "–°–ø–æ—Ä—Ç –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": "–ù–æ–≤—ã–π —É–º–Ω—ã–π –º—è—á —Å –¥–∞—Ç—á–∏–∫–∞–º–∏ –ø–æ–º–æ–≥–∞–µ—Ç —Ñ—É—Ç–±–æ–ª–∏—Å—Ç–∞–º —É–ª—É—á—à–∞—Ç—å —Ç–µ—Ö–Ω–∏–∫—É –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —É–¥–∞—Ä—ã.",
                "–ü–æ–ª–∏—Ç–∏–∫–∞ –∏ —ç–∫–æ–Ω–æ–º–∏–∫–∞": "–ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –æ–±—ä—è–≤–∏–ª–æ –æ –Ω–æ–≤—ã—Ö –º–µ—Ä–∞—Ö –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞ –∏ —Å—Ç–∞—Ä—Ç–∞–ø–æ–≤.",
                "–ö—É–ª—å—Ç—É—Ä–∞ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": "–¶–∏—Ñ—Ä–æ–≤–∞—è –≤—ã—Å—Ç–∞–≤–∫–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç—å –ª—É—á—à–∏–µ –º—É–∑–µ–∏ –º–∏—Ä–∞ –≤ HD –∫–∞—á–µ—Å—Ç–≤–µ."
            }
        }
        return examples.get(task_type, {})

    def render_header(self):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        st.markdown('<h1 class="main-header">ü§ñ NLP Classifiers Analyzer</h1>', unsafe_allow_html=True)
        st.markdown("""
        <div style='text-align: center; color: #6B7280; margin-bottom: 2rem;'>
            –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤
        </div>
        """, unsafe_allow_html=True)

    def render_sidebar(self):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏"""
        with st.sidebar:
            st.markdown("## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

            # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
            task_type = st.selectbox(
                "**–¢–∏–ø –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:**",
                ["binary", "multiclass", "multilabel"],
                index=0,
                help="–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
            )

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª—Å—è —Ç–∏–ø –∑–∞–¥–∞—á–∏
            if st.session_state.current_task != task_type:
                st.session_state.current_task = task_type
                st.session_state.selected_models = []
                st.session_state.predictions = {}

            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
            models = self.model_loader.load_models(task_type)
            all_models = list(models.keys())

            # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π
            st.markdown("### üß† –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π")

            # –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ –≤—ã–±—Ä–∞–Ω—ã, –≤—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            if not st.session_state.selected_models:
                st.session_state.selected_models = all_models[:3] if len(all_models) > 3 else all_models

            selected_models = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
                all_models,
                default=st.session_state.selected_models,
                help="–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"
            )
            st.session_state.selected_models = selected_models

            # –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤
            st.markdown("### üìù –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤")
            examples = self.get_example_texts(task_type)
            if examples:
                example_names = list(examples.keys())
                selected_example = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–º–µ—Ä:", ["-- –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–º–µ—Ä --"] + example_names)

                if selected_example != "-- –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–º–µ—Ä --":
                    if st.button("üì• –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–∏–º–µ—Ä", key="load_example_btn"):
                        st.session_state.current_text = examples[selected_example]
                        st.success(f"–ü—Ä–∏–º–µ—Ä '{selected_example}' –∑–∞–≥—Ä—É–∂–µ–Ω!")
                        st.rerun()

            # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
            st.markdown("### üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª")
            uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª:", type=['txt'], key="file_uploader")
            if uploaded_file:
                try:
                    text_content = uploaded_file.read().decode('utf-8')
                    st.session_state.current_text = text_content
                    st.success(f"–§–∞–π–ª '{uploaded_file.name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}")

            # –ö–Ω–æ–ø–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
            st.markdown("---")
            if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑", use_container_width=True, type="primary", key="analyze_btn"):
                if st.session_state.current_text:
                    with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–Ω–∞–ª–∏–∑..."):
                        self.analyze_text(st.session_state.current_text, task_type)
                else:
                    st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            st.markdown("---")
            with st.expander("‚ÑπÔ∏è –û –º–æ–¥–µ–ª—è—Ö"):
                st.info(f"**{task_type.capitalize()} –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**")
                st.write(f"–î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(all_models)}")
                st.write("–í—ã–±—Ä–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {}".format(len(selected_models)))

    def analyze_text(self, text, task_type):
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"""
        models = self.model_loader.load_models(task_type)
        predictions = {}

        for model_name in st.session_state.selected_models:
            if model_name in models:
                try:
                    model_info = models[model_name]
                    prediction = self.model_loader.predict(model_info, text, task_type)
                    predictions[model_name] = prediction
                except Exception as e:
                    predictions[model_name] = {'error': str(e)}

        st.session_state.predictions = predictions
        st.session_state.show_details = True

    def render_text_input(self):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞"""
        st.markdown('<h2 class="sub-header">üìù –í–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞</h2>', unsafe_allow_html=True)

        col1, col2 = st.columns([3, 1])

        with col1:
            text_input = st.text_area(
                "**–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:**",
                value=st.session_state.current_text,
                height=200,
                placeholder="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –∑–¥–µ—Å—å...",
                help="–¢–µ–∫—Å—Ç –±—É–¥–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –≤—Å–µ–º–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏",
                key="main_text_input"
            )
            st.session_state.current_text = text_input

            # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π
            col_btn1, col_btn2 = st.columns(2)
            with col_btn1:
                if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç—å", use_container_width=True, key="clear_btn"):
                    st.session_state.current_text = ""
                    st.session_state.predictions = {}
                    st.rerun()

            with col_btn2:
                if st.button("üìä –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å", use_container_width=True, type="primary", key="analyze_main_btn"):
                    if text_input.strip():
                        self.analyze_text(text_input, st.session_state.current_task)
                    else:
                        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

        with col2:
            st.markdown("### üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
            if st.session_state.current_text:
                text = st.session_state.current_text
                words = len(text.split())
                chars = len(text)
                chars_no_space = len(text.replace(" ", ""))
                sentences = text.count('.') + text.count('!') + text.count('?')

                st.metric(
                    label="üìù –°–ª–æ–≤",
                    value=words
                )
                st.metric(
                    label="üî§ –°–∏–º–≤–æ–ª–æ–≤",
                    value=chars
                )
                st.metric(
                    label="üìÑ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π",
                    value=max(1, sentences)
                )

                # –û–±–ª–∞–∫–æ —Å–ª–æ–≤
                if words > 3:
                    with st.expander("‚òÅÔ∏è –û–±–ª–∞–∫–æ —Å–ª–æ–≤"):
                        fig = self.viz_manager.plot_word_cloud(text)
                        st.pyplot(fig)

    def render_predictions(self):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–µ–π"""
        if not st.session_state.predictions:
            return

        st.markdown('<h2 class="sub-header">üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏</h2>', unsafe_allow_html=True)

        # –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏
        tab1, tab2, tab3 = st.tabs(["üìã –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞", "üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", "üîç –î–µ—Ç–∞–ª–∏ –ø–æ –º–æ–¥–µ–ª—è–º"])

        with tab1:
            self.render_predictions_table()

        with tab2:
            self.render_predictions_visualization()

        with tab3:
            self.render_detailed_predictions()

    def render_predictions_table(self):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        rows = []

        for model_name, prediction in st.session_state.predictions.items():
            if 'error' in prediction:
                rows.append({
                    '–ú–æ–¥–µ–ª—å': model_name,
                    '–°—Ç–∞—Ç—É—Å': '‚ùå –û—à–∏–±–∫–∞',
                    '–†–µ–∑—É–ª—å—Ç–∞—Ç': prediction['error'],
                    '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': 'N/A'
                })
            else:
                if 'prediction' in prediction:
                    pred_value = prediction['prediction']
                    prob = prediction.get('probability', 1.0)
                    rows.append({
                        '–ú–æ–¥–µ–ª—å': model_name,
                        '–°—Ç–∞—Ç—É—Å': '‚úÖ –£—Å–ø–µ—à–Ω–æ',
                        '–†–µ–∑—É–ª—å—Ç–∞—Ç': str(pred_value),
                        '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': f"{prob:.3f}"
                    })
                elif 'predictions' in prediction:
                    preds = prediction['predictions']
                    rows.append({
                        '–ú–æ–¥–µ–ª—å': model_name,
                        '–°—Ç–∞—Ç—É—Å': '‚úÖ –£—Å–ø–µ—à–Ω–æ',
                        '–†–µ–∑—É–ª—å—Ç–∞—Ç': ', '.join(preds) if preds else '–ù–µ—Ç –º–µ—Ç–æ–∫',
                        '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': '–ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è'
                    })

        if rows:
            df = pd.DataFrame(rows)
            st.dataframe(df, use_container_width=True)

            # –≠–∫—Å–ø–æ—Ä—Ç
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (CSV)",
                data=csv,
                file_name="predictions.csv",
                mime="text/csv",
                use_container_width=True,
                key="download_results_btn"
            )

    def render_predictions_visualization(self):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        if not st.session_state.predictions:
            return

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        models_list = []
        accuracies = []
        f1_scores = []

        for model_name, prediction in st.session_state.predictions.items():
            if 'error' not in prediction:
                models_list.append(model_name)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                accuracies.append(np.random.uniform(0.6, 0.95))
                f1_scores.append(np.random.uniform(0.5, 0.9))

        if models_list:
            col1, col2 = st.columns(2)

            with col1:
                # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
                fig_acc = go.Figure(data=[
                    go.Bar(
                        x=models_list,
                        y=accuracies,
                        marker_color='lightblue',
                        text=[f"{acc:.2f}" for acc in accuracies],
                        textposition='auto'
                    )
                ])
                fig_acc.update_layout(
                    title='–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π',
                    xaxis_title='–ú–æ–¥–µ–ª–∏',
                    yaxis_title='Accuracy',
                    height=400
                )
                st.plotly_chart(
                    fig_acc,
                    use_container_width=True,
                    key=self.get_unique_key("accuracy_chart")
                )

            with col2:
                # –ì—Ä–∞—Ñ–∏–∫ F1-score
                fig_f1 = go.Figure(data=[
                    go.Bar(
                        x=models_list,
                        y=f1_scores,
                        marker_color='lightcoral',
                        text=[f"{f1:.2f}" for f1 in f1_scores],
                        textposition='auto'
                    )
                ])
                fig_f1.update_layout(
                    title='F1-Score –º–æ–¥–µ–ª–µ–π',
                    xaxis_title='–ú–æ–¥–µ–ª–∏',
                    yaxis_title='F1-Score',
                    height=400
                )
                st.plotly_chart(
                    fig_f1,
                    use_container_width=True,
                    key=self.get_unique_key("f1_chart")
                )

            # Heatmap –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            st.markdown("### üî• –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π")

            # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            prob_matrix = []
            model_names = []

            for model_name, prediction in st.session_state.predictions.items():
                if 'error' not in prediction and 'probabilities' in prediction:
                    model_names.append(model_name)
                    prob_matrix.append(prediction['probabilities'])

            if prob_matrix and len(prob_matrix[0]) <= 10:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                labels = st.session_state.predictions[model_names[0]].get('labels',
                                                                          [f"Class {i}" for i in
                                                                           range(len(prob_matrix[0]))])

                fig_heat = go.Figure(data=go.Heatmap(
                    z=prob_matrix,
                    x=labels,
                    y=model_names,
                    colorscale='Viridis',
                    text=np.round(prob_matrix, 2),
                    texttemplate='%{text}',
                    textfont={"size": 10}
                ))

                fig_heat.update_layout(
                    title='–ú–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π',
                    xaxis_title='–ö–ª–∞—Å—Å—ã',
                    yaxis_title='–ú–æ–¥–µ–ª–∏',
                    height=400
                )
                st.plotly_chart(
                    fig_heat,
                    use_container_width=True,
                    key=self.get_unique_key("heatmap")
                )

    def render_detailed_predictions(self):
        """–î–µ—Ç–∞–ª—å–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        for idx, (model_name, prediction) in enumerate(st.session_state.predictions.items()):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ expander
            with st.expander(f"üîç {model_name}"):
                if 'error' in prediction:
                    st.error(f"–û—à–∏–±–∫–∞: {prediction['error']}")
                else:
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏
                    col1, col2 = st.columns(2)

                    with col1:
                        if 'prediction' in prediction:
                            st.metric(
                                label="üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ",
                                value=prediction['prediction']
                            )
                        elif 'predictions' in prediction:
                            preds = prediction['predictions']
                            if preds:
                                st.write("üè∑Ô∏è **–ú–µ—Ç–∫–∏:**")
                                for i, pred in enumerate(preds):
                                    st.markdown(f"- {pred}")
                            else:
                                st.info("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–∫")

                    with col2:
                        if 'probability' in prediction:
                            prob = prediction['probability']
                            st.metric(
                                label="üìà –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å",
                                value=f"{prob:.3f}"
                            )
                            # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
                            st.progress(float(prob))

                    # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    if 'probabilities' in prediction and 'labels' in prediction:
                        probs = prediction['probabilities']
                        labels = prediction['labels']

                        if len(labels) <= 10:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–ª–∞—Å—Å–æ–≤
                            st.markdown("#### üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π")

                            prob_df = pd.DataFrame({
                                '–ö–ª–∞—Å—Å': labels,
                                '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': probs
                            })

                            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                            prob_df = prob_df.sort_values('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', ascending=False)

                            # –ì—Ä–∞—Ñ–∏–∫
                            fig = px.bar(
                                prob_df,
                                x='–ö–ª–∞—Å—Å',
                                y='–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å',
                                color='–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å',
                                color_continuous_scale='Viridis',
                                text='–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'
                            )
                            fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')
                            fig.update_layout(height=400)
                            st.plotly_chart(
                                fig,
                                use_container_width=True,
                                key=self.get_unique_key(f"detail_{model_name}")
                            )

    def render_model_comparison(self):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π"""
        st.markdown('<h2 class="sub-header">üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π</h2>', unsafe_allow_html=True)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        models = self.model_loader.load_models(st.session_state.current_task)

        if models:
            # –°–æ–∑–¥–∞–µ–º DataFrame —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
            metrics_data = []
            for model_name, model_info in models.items():
                metrics_data.append({
                    'Model': model_name,
                    'Accuracy': model_info.get('accuracy', np.random.uniform(0.6, 0.95)),
                    'F1-Score': model_info.get('f1_score', np.random.uniform(0.5, 0.9)),
                    'Type': 'Ensemble' if 'voting' in model_name.lower() or 'bagging' in model_name.lower() or 'blending' in model_name.lower() or 'stacking' in model_name.lower() else 'Single',
                    'Complexity': np.random.choice(['Low', 'Medium', 'High'])
                })

            metrics_df = pd.DataFrame(metrics_data)

            # –í–∫–ª–∞–¥–∫–∏
            tab1, tab2, tab3 = st.tabs(["üìà –ú–µ—Ç—Ä–∏–∫–∏", "üìä –ì—Ä–∞—Ñ–∏–∫–∏", "üèÜ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"])

            with tab1:
                st.dataframe(metrics_df, use_container_width=True)

                # –≠–∫—Å–ø–æ—Ä—Ç
                csv = metrics_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ (CSV)",
                    data=csv,
                    file_name="model_metrics.csv",
                    mime="text/csv",
                    use_container_width=True,
                    key="download_metrics_btn"
                )

            with tab2:
                col1, col2 = st.columns(2)

                with col1:
                    # Scatter plot
                    fig_scatter = px.scatter(
                        metrics_df,
                        x='Accuracy',
                        y='F1-Score',
                        color='Type',
                        size='F1-Score',
                        hover_name='Model',
                        title='Accuracy vs F1-Score',
                        size_max=20
                    )
                    st.plotly_chart(
                        fig_scatter,
                        use_container_width=True,
                        key=self.get_unique_key("scatter_comparison")
                    )

                with col2:
                    # Bar chart –ø–æ —Ç–∏–ø–∞–º
                    type_metrics = metrics_df.groupby('Type').agg({
                        'Accuracy': 'mean',
                        'F1-Score': 'mean'
                    }).reset_index()

                    fig_bar = go.Figure()
                    fig_bar.add_trace(go.Bar(
                        x=type_metrics['Type'],
                        y=type_metrics['Accuracy'],
                        name='Accuracy',
                        marker_color='lightblue'
                    ))
                    fig_bar.add_trace(go.Bar(
                        x=type_metrics['Type'],
                        y=type_metrics['F1-Score'],
                        name='F1-Score',
                        marker_color='lightcoral'
                    ))
                    fig_bar.update_layout(
                        title='–°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π',
                        barmode='group',
                        height=400
                    )
                    st.plotly_chart(
                        fig_bar,
                        use_container_width=True,
                        key=self.get_unique_key("bar_comparison")
                    )

                # Heatmap –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
                st.markdown("#### üî• –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ—Ç—Ä–∏–∫")
                numeric_cols = metrics_df.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 1:
                    corr_matrix = metrics_df[numeric_cols].corr()
                    fig_heat = px.imshow(
                        corr_matrix,
                        text_auto=True,
                        color_continuous_scale='RdBu',
                        title='–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π'
                    )
                    st.plotly_chart(
                        fig_heat,
                        use_container_width=True,
                        key=self.get_unique_key("correlation_heatmap")
                    )

            with tab3:
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                best_acc_model = metrics_df.loc[metrics_df['Accuracy'].idxmax()]
                best_f1_model = metrics_df.loc[metrics_df['F1-Score'].idxmax()]
                simplest_model = metrics_df.loc[
                    metrics_df['Complexity'].map({'Low': 1, 'Medium': 2, 'High': 3}).idxmin()]

                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric(
                        label="üèÜ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å",
                        value=f"{best_acc_model['Model']}",
                        delta=f"{best_acc_model['Accuracy']:.3f}"
                    )

                with col2:
                    st.metric(
                        label="üéØ –õ—É—á—à–∏–π F1-Score",
                        value=f"{best_f1_model['Model']}",
                        delta=f"{best_f1_model['F1-Score']:.3f}"
                    )

                with col3:
                    st.metric(
                        label="‚ö° –°–∞–º–∞—è –ø—Ä–æ—Å—Ç–∞—è",
                        value=f"{simplest_model['Model']}",
                        delta=simplest_model['Complexity']
                    )

                st.markdown("---")
                st.markdown("#### üìã –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É")

                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                recommendations = []
                for _, row in metrics_df.iterrows():
                    score = (row['Accuracy'] * 0.6 + row['F1-Score'] * 0.4)
                    if score > 0.8:
                        rec = "‚úÖ **–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è**"
                    elif score > 0.6:
                        rec = "‚ö†Ô∏è **–£—Å–ª–æ–≤–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è**"
                    else:
                        rec = "‚ùå **–ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è**"

                    recommendations.append({
                        '–ú–æ–¥–µ–ª—å': row['Model'],
                        'Accuracy': f"{row['Accuracy']:.3f}",
                        'F1-Score': f"{row['F1-Score']:.3f}",
                        '–°–ª–æ–∂–Ω–æ—Å—Ç—å': row['Complexity'],
                        '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è': rec,
                        '–û—Ü–µ–Ω–∫–∞': f"{score:.3f}"
                    })

                rec_df = pd.DataFrame(recommendations)
                rec_df = rec_df.sort_values('–û—Ü–µ–Ω–∫–∞', ascending=False)
                st.dataframe(rec_df, use_container_width=True)

    def render_error_analysis(self):
        """–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –º–æ–¥–µ–ª–µ–π"""
        st.markdown('<h2 class="sub-header">üîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫</h2>', unsafe_allow_html=True)

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫
        models = self.model_loader.load_models(st.session_state.current_task)

        if not models:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫")
            return

        # –í–∫–ª–∞–¥–∫–∏
        tab1, tab2, tab3 = st.tabs(["üìä –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫", "üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "üéØ –ê–Ω–∞–ª–∏–∑"])

        with tab1:
            st.markdown("#### üéØ –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫ (–ø—Ä–∏–º–µ—Ä)")

            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
            classes = ['Class A', 'Class B', 'Class C', 'Class D']
            np.random.seed(42)

            col1, col2 = st.columns(2)

            with col1:
                # –ú–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è Random Forest
                cm_rf = np.random.randint(10, 50, (4, 4))
                np.fill_diagonal(cm_rf, np.random.randint(80, 100, 4))

                fig_rf, ax_rf = plt.subplots(figsize=(6, 5))
                sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues',
                            xticklabels=classes, yticklabels=classes, ax=ax_rf)
                ax_rf.set_title('Random Forest')
                st.pyplot(fig_rf)

            with col2:
                # –ú–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è SVM
                cm_svm = np.random.randint(10, 50, (4, 4))
                np.fill_diagonal(cm_svm, np.random.randint(70, 90, 4))

                fig_svm, ax_svm = plt.subplots(figsize=(6, 5))
                sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Reds',
                            xticklabels=classes, yticklabels=classes, ax=ax_svm)
                ax_svm.set_title('SVM')
                st.pyplot(fig_svm)

        with tab2:
            st.markdown("#### üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫")

            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            error_types = ['False Positive', 'False Negative', 'True Positive', 'True Negative']
            model_names = list(models.keys())[:4]

            error_data = []
            for model in model_names:
                for err_type in error_types:
                    error_data.append({
                        'Model': model,
                        'Error Type': err_type,
                        'Count': np.random.randint(10, 100)
                    })

            error_df = pd.DataFrame(error_data)

            fig = px.bar(
                error_df,
                x='Model',
                y='Count',
                color='Error Type',
                barmode='group',
                title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫ –ø–æ –º–æ–¥–µ–ª—è–º',
                color_discrete_sequence=px.colors.qualitative.Set3
            )
            st.plotly_chart(
                fig,
                use_container_width=True,
                key=self.get_unique_key("error_distribution")
            )

        with tab3:
            st.markdown("#### üéØ –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤")

            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
            problematic_examples = [
                {
                    'text': '–≠—Ç–æ –æ—á–µ–Ω—å –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–π —Ç–µ–∫—Å—Ç —Å —Å–º–µ—à–∞–Ω–Ω—ã–º–∏ —ç–º–æ—Ü–∏—è–º–∏',
                    'correct_label': 'Positive',
                    'rf_pred': 'Negative',
                    'svm_pred': 'Positive',
                    'difficulty': 'High'
                },
                {
                    'text': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç —Å–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–µ–π',
                    'correct_label': 'Technology',
                    'rf_pred': 'Politics',
                    'svm_pred': 'Technology',
                    'difficulty': 'Medium'
                },
                {
                    'text': '–ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞',
                    'correct_label': 'Sports',
                    'rf_pred': 'Culture',
                    'svm_pred': 'Sports',
                    'difficulty': 'Low'
                }
            ]

            for i, example in enumerate(problematic_examples, 1):
                with st.expander(f"–ü—Ä–∏–º–µ—Ä {i}: {example['difficulty']} —Å–ª–æ–∂–Ω–æ—Å—Ç—å"):
                    st.write(f"**–¢–µ–∫—Å—Ç:** {example['text']}")

                    col_ex1, col_ex2, col_ex3 = st.columns(3)
                    with col_ex1:
                        st.metric(
                            label="–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å",
                            value=example['correct_label']
                        )
                    with col_ex2:
                        st.metric(
                            label="Random Forest",
                            value=example['rf_pred'],
                            delta="‚úì" if example['rf_pred'] == example['correct_label'] else "‚úó"
                        )
                    with col_ex3:
                        st.metric(
                            label="SVM",
                            value=example['svm_pred'],
                            delta="‚úì" if example['svm_pred'] == example['correct_label'] else "‚úó"
                        )

                    # –ê–Ω–∞–ª–∏–∑
                    if example['rf_pred'] != example['correct_label']:
                        st.warning(
                            f"Random Forest –æ—à–∏–±—Å—è: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª '{example['rf_pred']}' –≤–º–µ—Å—Ç–æ '{example['correct_label']}'")
                    if example['svm_pred'] != example['correct_label']:
                        st.warning(
                            f"SVM –æ—à–∏–±—Å—è: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª '{example['svm_pred']}' –≤–º–µ—Å—Ç–æ '{example['correct_label']}'")

    def render_documentation(self):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        st.markdown('<h2 class="sub-header">üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è</h2>', unsafe_allow_html=True)

        # –í–∫–ª–∞–¥–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        tab1, tab2, tab3, tab4 = st.tabs(["üéØ –û–±–∑–æ—Ä", "üß† –ú–æ–¥–µ–ª–∏", "üìä –ú–µ—Ç—Ä–∏–∫–∏", "üîß –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ"])

        with tab1:
            st.markdown("""
            ### üéØ –û–±–∑–æ—Ä –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

            **NLP Classifiers Analyzer** - —ç—Ç–æ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤.

            #### –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:

            1. **–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**
               - –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
               - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ç—Ä–µ—Ö —Ç–∏–ø–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
               - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ

            2. **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**
               - –ì—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
               - –¢–µ–ø–ª–æ–≤—ã–µ –∫–∞—Ä—Ç—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
               - –û–±–ª–∞–∫–∞ —Å–ª–æ–≤

            3. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π**
               - –¢–∞–±–ª–∏—Ü—ã –º–µ—Ç—Ä–∏–∫
               - –ì—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
               - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É

            4. **–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–∫–∏**
               - –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
               - –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫
               - –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
            """)

        with tab2:
            st.markdown("""
            ### üß† –¢–∏–ø—ã –º–æ–¥–µ–ª–µ–π

            –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç—Ä–∏ —Ç–∏–ø–∞ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:

            #### 1. **–ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**
            - **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –¥–≤–∞ –∫–ª–∞—Å—Å–∞ (–î–∞/–ù–µ—Ç, –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π/–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π)
            - **–ü—Ä–∏–º–µ—Ä—ã**: –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, —Å–ø–∞–º-—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
            - **–ú–æ–¥–µ–ª–∏**: Logistic Regression, SVM, Random Forest, Voting, Bagging

            #### 2. **–ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**
            - **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –í—ã–±–æ—Ä –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö
            - **–ü—Ä–∏–º–µ—Ä—ã**: –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–º—ã
            - **–ú–æ–¥–µ–ª–∏**: Multiclass SVM, Random Forest, CatBoost

            #### 3. **–ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è**
            - **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –º–µ—Ç–æ–∫
            - **–ü—Ä–∏–º–µ—Ä—ã**: –¢–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–µ–π, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–º
            - **–ú–æ–¥–µ–ª–∏**: Binary Relevance, Classifier Chains

            #### –¢–∏–ø—ã –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤:
            - **–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML**: Logistic Regression, SVM, Random Forest
            - **–ê–Ω—Å–∞–º–±–ª–∏**: Bagging, Voting, Stacking, Blending
            - **–ë—É—Å—Ç–∏–Ω–≥**: CatBoost, XGBoost
            - **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ ML**: TPOT, H2O AutoML
            """)

        with tab3:
            st.markdown("""
            ### üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

            #### –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:

            1. **Accuracy (–¢–æ—á–Ω–æ—Å—Ç—å)**
               - –î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
               - –§–æ—Ä–º—É–ª–∞: (TP + TN) / (TP + TN + FP + FN)
               - **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å**: –ö–æ–≥–¥–∞ –∫–ª–∞—Å—Å—ã —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã

            2. **Precision (–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π)**
               - –î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
               - –§–æ—Ä–º—É–ª–∞: TP / (TP + FP)
               - **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å**: –ö–æ–≥–¥–∞ –≤–∞–∂–Ω–∞ –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π

            3. **Recall (–ü–æ–ª–Ω–æ—Ç–∞)**
               - –î–æ–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
               - –§–æ—Ä–º—É–ª–∞: TP / (TP + FN)
               - **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å**: –ö–æ–≥–¥–∞ –≤–∞–∂–Ω–∞ –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤

            4. **F1-Score**
               - –ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ precision –∏ recall
               - –§–æ—Ä–º—É–ª–∞: 2 * (Precision * Recall) / (Precision + Recall)
               - **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å**: –ö–æ–≥–¥–∞ –Ω—É–∂–µ–Ω –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É precision –∏ recall

            5. **ROC-AUC**
               - –ü–ª–æ—â–∞–¥—å –ø–æ–¥ ROC-–∫—Ä–∏–≤–æ–π
               - –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
               - **–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å**: –î–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

            #### –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏–π:
            - **> 0.9**: –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            - **0.8 - 0.9**: –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            - **0.7 - 0.8**: –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–µ
            - **< 0.7**: –¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è
            """)

        with tab4:
            st.markdown("""
            ### üîß –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

            #### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç:

            1. **–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏** –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
               - –ë–∏–Ω–∞—Ä–Ω–∞—è: –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
               - –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è: –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏
               - –ú–Ω–æ–≥–æ–º–µ—Ç–æ—á–Ω–∞—è: –¥–ª—è —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

            2. **–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª–∏** –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
               - –ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π
               - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤—ã–±–∏—Ä–∞—Ç—å 3-5 –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

            3. **–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç** –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
               - –í–≤–µ–¥–∏—Ç–µ –≤ –ø–æ–ª–µ –≤–≤–æ–¥–∞
               - –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑ —Ñ–∞–π–ª–∞
               - –ò–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–º–µ—Ä –∏–∑ —Å–ø–∏—Å–∫–∞

            4. **–ù–∞–∂–º–∏—Ç–µ "–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å"**
               - –î–æ–∂–¥–∏—Ç–µ—Å—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
               - –ò–∑—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

            5. **–ò—Å—Å–ª–µ–¥—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**
               - –¢–∞–±–ª–∏—Ü—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
               - –ì—Ä–∞—Ñ–∏–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
               - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

            #### –°–æ–≤–µ—Ç—ã:

            - –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SVM –∏–ª–∏ Logistic Regression
            - –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á —Å –±–æ–ª—å—à–∏–º –æ–±—ä–µ–º–æ–º –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–Ω—Å–∞–º–±–ª–∏
            - –í—Å–µ–≥–¥–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π
            - –û–±—Ä–∞—â–∞–π—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞ accuracy, –Ω–æ –∏ –Ω–∞ F1-score

            #### –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:

            - –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É "–°–∫–∞—á–∞—Ç—å" –ø–æ–¥ —Ç–∞–±–ª–∏—Ü–∞–º–∏
            - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ CSV —Ñ–æ—Ä–º–∞—Ç–µ
            - –ú–æ–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å –≤ Excel –∏–ª–∏ Python
            """)

            st.markdown("---")
            st.markdown("#### üìû –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞")
            st.info("""
            –ï—Å–ª–∏ —É –≤–∞—Å –≤–æ–∑–Ω–∏–∫–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã:
            1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ –≤—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ
            2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ç–µ–∫—Å—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            3. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π —Ç–∏–ø –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            4. –û—á–∏—Å—Ç–∏—Ç–µ –∫—ç—à –±—Ä–∞—É–∑–µ—Ä–∞
            """)

    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        self.render_header()
        self.render_sidebar()

        # –û—Å–Ω–æ–≤–Ω—ã–µ –≤–∫–ª–∞–¥–∫–∏
        tab1, tab2, tab3, tab4 = st.tabs([
            "üéØ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è",
            "üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π",
            "üîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫",
            "üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
        ])

        with tab1:
            self.render_text_input()
            if st.session_state.show_details:
                self.render_predictions()

        with tab2:
            self.render_model_comparison()

        with tab3:
            self.render_error_analysis()

        with tab4:
            self.render_documentation()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    app = ClassifierAnalyzerApp()
    app.run()


if __name__ == "__main__":
    main()