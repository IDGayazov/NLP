from rank_bm25 import BM25Okapi
import numpy as np

from util.decribe import get_dataset


class BM25VectorizerShort:
    """
    –ö–æ—Ä–æ—Ç–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è BM25 –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
    """

    def __init__(self, k1=1.5, b=0.75):
        self.bm25 = None
        self.k1 = k1
        self.b = b
        self.vocabulary_ = None

    def fit_transform(self, texts):
        """–û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –≤ BM25 –º–∞—Ç—Ä–∏—Ü—É"""
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤
        tokenized_texts = [text.split() for text in texts]

        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å
        self.vocabulary_ = set()
        for tokens in tokenized_texts:
            self.vocabulary_.update(tokens)
        self.vocabulary_ = list(self.vocabulary_)

        # –û–±—É—á–∞–µ–º BM25
        self.bm25 = BM25Okapi(tokenized_texts, k1=self.k1, b=self.b)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –º–∞—Ç—Ä–∏—Ü—É scores
        scores = []
        for tokens in tokenized_texts:
            doc_scores = self.bm25.get_scores(tokens)
            scores.append(doc_scores)

        return np.array(scores)

    def transform(self, texts):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –≤ BM25 –º–∞—Ç—Ä–∏—Ü—É"""
        if self.bm25 is None:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ fit_transform!")

        tokenized_texts = [text.split() for text in texts]

        scores = []
        for tokens in tokenized_texts:
            doc_scores = self.bm25.get_scores(tokens)
            scores.append(doc_scores)

        return np.array(scores)

    def get_feature_names(self):
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ç–æ–∫–µ–Ω—ã)"""
        return self.vocabulary_ if self.vocabulary_ is not None else []

    def get_vocabulary_size(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è"""
        return len(self.vocabulary_) if self.vocabulary_ is not None else 0


if __name__ == "__main__":
    data = get_dataset()

    texts = []
    for item in data:
        texts.append(item['text'])

    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º BM25
    bm25 = BM25VectorizerShort()
    X = bm25.fit_transform(texts)

    print(f"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {X.shape}")
    print(f"üî§ –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {bm25.get_vocabulary_size()}")
    print(f"üìù –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {bm25.get_feature_names()[:10]}")