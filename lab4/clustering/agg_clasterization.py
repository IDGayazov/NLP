import time

import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import AgglomerativeClustering
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import (silhouette_score, calinski_harabasz_score,
                             davies_bouldin_score, adjusted_rand_score,
                             normalized_mutual_info_score, v_measure_score)
from scipy.sparse import issparse
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.spatial.distance import pdist

from util.decribe import get_labels, get_texts


def compare_agglomerative_clustering(texts, true_labels=None, max_k=6, linkage_types=None):
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ AgglomerativeClustering —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ —Å–≤—è–∑–µ–π
    """
    vectorizer = TfidfVectorizer(max_features=500)
    X = vectorizer.fit_transform(texts)

    # –î–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫ –Ω—É–∂–Ω—ã –ø–ª–æ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    X_dense = X.toarray() if issparse(X) else X

    has_true_labels = true_labels is not None

    if linkage_types is None:
        linkage_types = ['ward', 'average', 'complete', 'single']

    if has_true_labels:
        print("üî¨ AGGLOMERATIVE CLUSTERING –° –í–ù–£–¢–†–ï–ù–ù–ò–ú–ò –ò –í–ù–ï–®–ù–ò–ú–ò –ú–ï–¢–†–ò–ö–ê–ú–ò:")
        print("k\tLinkage\tSilhouette\tCalinski\tDavies-B\tARI\t\tNMI\t\tV-measure")
        print("-" * 95)
    else:
        print("üî¨ AGGLOMERATIVE CLUSTERING –° –í–ù–£–¢–†–ï–ù–ù–ò–ú–ò –ú–ï–¢–†–ò–ö–ê–ú–ò:")
        print("k\tLinkage\tSilhouette\tCalinski\tDavies-B")
        print("-" * 65)

    results = []

    for k in range(2, max_k + 1):
        for linkage_type in linkage_types:
            try:
                start_time = time.time()

                if linkage_type == 'ward':
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º sklearn –¥–ª—è ward (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø–ª–æ—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏)
                    agglo = AgglomerativeClustering(
                        n_clusters=k,
                        linkage='ward',
                        metric='euclidean'
                    )
                    labels = agglo.fit_predict(X_dense)
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö linkage –∏—Å–ø–æ–ª—å–∑—É–µ–º scipy.hierarchy
                    # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–ø–∞—Ä–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
                    if linkage_type in ['average', 'complete', 'single']:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤
                        distances = pdist(X_dense, metric='cosine')
                    else:
                        distances = pdist(X_dense, metric='euclidean')

                    # –°—Ç—Ä–æ–∏–º –∏–µ—Ä–∞—Ä—Ö–∏—é
                    Z = linkage(distances, method=linkage_type)
                    # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã
                    labels = fcluster(Z, k, criterion='maxclust') - 1  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ 0-based

                fit_time = time.time() - start_time

                # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤—Å–µ–≥–¥–∞ –Ω–∞ –ø–ª–æ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                silhouette = silhouette_score(X_dense, labels)
                calinski = calinski_harabasz_score(X_dense, labels)
                davies = davies_bouldin_score(X_dense, labels)

                if has_true_labels:
                    # –í–Ω–µ—à–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                    ari = adjusted_rand_score(true_labels, labels)
                    nmi = normalized_mutual_info_score(true_labels, labels)
                    v_measure = v_measure_score(true_labels, labels)

                    print(f"{k}\t{linkage_type}\t{silhouette:.3f}\t\t{calinski:.3f}\t\t{davies:.3f}\t\t"
                          f"{ari:.3f}\t\t{nmi:.3f}\t\t{v_measure:.3f}")
                else:
                    print(f"{k}\t{linkage_type}\t{silhouette:.3f}\t\t{calinski:.3f}\t\t{davies:.3f}")

                results.append({
                    'k': k,
                    'linkage': linkage_type,
                    'silhouette': silhouette,
                    'calinski': calinski,
                    'davies': davies,
                    'ari': ari if has_true_labels else -1,
                    'nmi': nmi if has_true_labels else -1,
                    'v_measure': v_measure if has_true_labels else -1,
                    'labels': labels,
                    'fit_time': fit_time
                })

            except Exception as e:
                error_msg = str(e)
                print(f"{k}\t{linkage_type}\tERROR: {error_msg[:40]}...")

    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    if results:
        best_by_silhouette = max(results, key=lambda x: x['silhouette'])
        if has_true_labels:
            best_by_ari = max(results, key=lambda x: x['ari'])

        print(f"\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print(f"   –ü–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –º–µ—Ç—Ä–∏–∫–∞–º: k={best_by_silhouette['k']}, "
              f"linkage={best_by_silhouette['linkage']} "
              f"(Silhouette: {best_by_silhouette['silhouette']:.3f})")
        if has_true_labels:
            print(f"   –ü–æ –≤–Ω–µ—à–Ω–∏–º –º–µ—Ç—Ä–∏–∫–∞–º: k={best_by_ari['k']}, "
                  f"linkage={best_by_ari['linkage']} "
                  f"(ARI: {best_by_ari['ari']:.3f})")
    else:
        print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é")
        best_by_silhouette = best_by_ari = None

    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏
    if has_true_labels and results:
        _plot_agglomerative_metrics(results, texts, true_labels, best_by_silhouette, best_by_ari)
    elif results:
        _plot_agglomerative_internal_metrics(results, best_by_silhouette)

    if has_true_labels and results:
        return best_by_silhouette, best_by_ari
    elif results:
        return best_by_silhouette
    else:
        return None, None if has_true_labels else None


def _plot_agglomerative_metrics(results, texts, true_labels, best_silhouette, best_ari):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è AgglomerativeClustering —Å–æ –≤—Å–µ–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8))

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    linkage_types = sorted(set(r['linkage'] for r in results))
    k_values = sorted(set(r['k'] for r in results))

    # –ì—Ä–∞—Ñ–∏–∫ 1: Silhouette Score –¥–ª—è —Ä–∞–∑–Ω—ã—Ö linkage
    for linkage_type in linkage_types:
        linkage_data = [r for r in results if r['linkage'] == linkage_type]
        if linkage_data:
            k_vals = [r['k'] for r in linkage_data]
            silhouette_vals = [r['silhouette'] for r in linkage_data]
            ax1.plot(k_vals, silhouette_vals, 'o-', linewidth=2, markersize=6,
                     label=f'{linkage_type}')

    if best_silhouette:
        ax1.axvline(x=best_silhouette['k'], color='red', linestyle='--', alpha=0.7,
                    label=f'–õ—É—á—à–µ–µ k={best_silhouette["k"]}')

    ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax1.set_ylabel('Silhouette Score')
    ax1.set_title('AGGLOMERATIVE: SILHOUETTE SCORE\n(‚Üë –ª—É—á—à–µ)')
    ax1.grid(True, alpha=0.3)
    ax1.legend()

    # –ì—Ä–∞—Ñ–∏–∫ 2: –í–Ω–µ—à–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (ARI)
    for linkage_type in linkage_types:
        linkage_data = [r for r in results if r['linkage'] == linkage_type and r['ari'] > -1]
        if linkage_data:
            k_vals = [r['k'] for r in linkage_data]
            ari_vals = [r['ari'] for r in linkage_data]
            ax2.plot(k_vals, ari_vals, 'o-', linewidth=2, markersize=6,
                     label=f'{linkage_type}')

    if best_ari:
        ax2.axvline(x=best_ari['k'], color='red', linestyle='--', alpha=0.7,
                    label=f'–õ—É—á—à–µ–µ k={best_ari["k"]}')

    ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax2.set_ylabel('ARI Score')
    ax2.set_title('AGGLOMERATIVE: ADJUSTED RAND INDEX\n(‚Üë –ª—É—á—à–µ)')
    ax2.grid(True, alpha=0.3)
    ax2.legend()

    # –ì—Ä–∞—Ñ–∏–∫ 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –ª—É—á—à–µ–≥–æ linkage
    if results:
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π linkage –ø–æ silhouette
        best_linkage_data = {}
        for linkage_type in linkage_types:
            linkage_results = [r for r in results if r['linkage'] == linkage_type]
            if linkage_results:
                best_for_linkage = max(linkage_results, key=lambda x: x['silhouette'])
                best_linkage_data[linkage_type] = best_for_linkage

        if best_linkage_data:
            linkages = list(best_linkage_data.keys())
            silhouettes = [best_linkage_data[linkage]['silhouette'] for linkage in linkages]
            aris = [best_linkage_data[linkage]['ari'] for linkage in linkages] if best_ari else [0] * len(linkages)

            x = np.arange(len(linkages))
            width = 0.35

            ax3.bar(x - width / 2, silhouettes, width, label='Silhouette', alpha=0.8)
            if best_ari:
                ax3.bar(x + width / 2, aris, width, label='ARI', alpha=0.8)

            ax3.set_xlabel('Linkage Type')
            ax3.set_ylabel('Score')
            ax3.set_title('–°–†–ê–í–ù–ï–ù–ò–ï LINKAGE –¢–ò–ü–û–í\n(–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ k)')
            ax3.set_xticks(x)
            ax3.set_xticklabels(linkages)
            ax3.legend()
            ax3.grid(True, alpha=0.3)

    # –ì—Ä–∞—Ñ–∏–∫ 4: –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    times = {}
    for linkage_type in linkage_types:
        linkage_times = []
        for k in k_values:
            linkage_results = [r for r in results if r['linkage'] == linkage_type and r['k'] == k]
            if linkage_results:
                linkage_times.append(linkage_results[0]['fit_time'])
        if linkage_times:
            times[linkage_type] = linkage_times

    for linkage_type, time_vals in times.items():
        if len(time_vals) == len(k_values):
            ax4.plot(k_values, time_vals, 'o-', linewidth=2, markersize=6, label=linkage_type)

    ax4.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax4.set_ylabel('–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (—Å–µ–∫—É–Ω–¥—ã)')
    ax4.set_title('AGGLOMERATIVE: –í–†–ï–ú–Ø –í–´–ü–û–õ–ù–ï–ù–ò–Ø')
    ax4.grid(True, alpha=0.3)
    ax4.legend()

    plt.tight_layout()
    plt.show()


def _plot_agglomerative_internal_metrics(results, best_params):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫
    """
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))

    linkage_types = sorted(set(r['linkage'] for r in results))
    k_values = sorted(set(r['k'] for r in results))

    # –ì—Ä–∞—Ñ–∏–∫ 1: Silhouette Score
    for linkage_type in linkage_types:
        linkage_data = [r for r in results if r['linkage'] == linkage_type]
        if linkage_data:
            k_vals = [r['k'] for r in linkage_data]
            silhouette_vals = [r['silhouette'] for r in linkage_data]
            ax1.plot(k_vals, silhouette_vals, 'o-', linewidth=2, markersize=6,
                     label=f'{linkage_type}')

    if best_params:
        ax1.axvline(x=best_params['k'], color='red', linestyle='--', alpha=0.7,
                    label=f'–õ—É—á—à–µ–µ k={best_params["k"]}')

    ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax1.set_ylabel('Silhouette Score')
    ax1.set_title('AGGLOMERATIVE: SILHOUETTE SCORE\n(‚Üë –ª—É—á—à–µ)')
    ax1.grid(True, alpha=0.3)
    ax1.legend()

    # –ì—Ä–∞—Ñ–∏–∫ 2: Calinski-Harabasz Score
    for linkage_type in linkage_types:
        linkage_data = [r for r in results if r['linkage'] == linkage_type]
        if linkage_data:
            k_vals = [r['k'] for r in linkage_data]
            calinski_vals = [r['calinski'] for r in linkage_data]
            ax2.plot(k_vals, calinski_vals, 'o-', linewidth=2, markersize=6,
                     label=f'{linkage_type}')

    ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax2.set_ylabel('Calinski-Harabasz Score')
    ax2.set_title('AGGLOMERATIVE: CALINSKI-HARABASZ\n(‚Üë –ª—É—á—à–µ)')
    ax2.grid(True, alpha=0.3)
    ax2.legend()

    # –ì—Ä–∞—Ñ–∏–∫ 3: Davies-Bouldin Score
    for linkage_type in linkage_types:
        linkage_data = [r for r in results if r['linkage'] == linkage_type]
        if linkage_data:
            k_vals = [r['k'] for r in linkage_data]
            davies_vals = [r['davies'] for r in linkage_data]
            ax3.plot(k_vals, davies_vals, 'o-', linewidth=2, markersize=6,
                     label=f'{linkage_type}')

    ax3.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax3.set_ylabel('Davies-Bouldin Score')
    ax3.set_title('AGGLOMERATIVE: DAVIES-BOULDIN\n(‚Üì –ª—É—á—à–µ)')
    ax3.grid(True, alpha=0.3)
    ax3.legend()

    plt.tight_layout()
    plt.show()


def simple_agglomerative_cluster(texts, n_clusters=3, linkage_type='ward'):
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤ —Å AgglomerativeClustering
    """
    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
    vectorizer = TfidfVectorizer(max_features=500)
    X = vectorizer.fit_transform(texts)
    X_dense = X.toarray() if issparse(X) else X

    start_time = time.time()

    if linkage_type == 'ward':
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º sklearn –¥–ª—è ward
        agglo = AgglomerativeClustering(
            n_clusters=n_clusters,
            linkage='ward',
            metric='euclidean'
        )
        labels = agglo.fit_predict(X_dense)
    else:
        # –î–ª—è –¥—Ä—É–≥–∏—Ö linkage –∏—Å–ø–æ–ª—å–∑—É–µ–º scipy.hierarchy
        if linkage_type in ['average', 'complete', 'single']:
            distances = pdist(X_dense, metric='cosine')
        else:
            distances = pdist(X_dense, metric='euclidean')

        Z = linkage(distances, method=linkage_type)
        labels = fcluster(Z, n_clusters, criterion='maxclust') - 1

    fit_time = time.time() - start_time

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    metrics = {
        'silhouette': silhouette_score(X_dense, labels),
        'calinski_harabasz': calinski_harabasz_score(X_dense, labels),
        'davies_bouldin': davies_bouldin_score(X_dense, labels),
        'linkage': linkage_type,
        'fit_time': fit_time
    }

    # –ü—Ä–æ—Å—Ç–æ–π –≤—ã–≤–æ–¥
    print(f"üìä AgglomerativeClustering –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ {n_clusters} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
    print(f"‚öôÔ∏è  –ü–ê–†–ê–ú–ï–¢–†–´: linkage={linkage_type}")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {fit_time:.2f} —Å–µ–∫")
    print(f"üéØ –ú–ï–¢–†–ò–ö–ò:")
    print(f"   Silhouette Score: {metrics['silhouette']:.3f}")
    print(f"   Calinski-Harabasz: {metrics['calinski_harabasz']:.3f}")
    print(f"   Davies-Bouldin: {metrics['davies_bouldin']:.3f}")

    # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è Silhouette Score
    silhouette_val = metrics['silhouette']
    if silhouette_val > 0.7:
        interpretation = "–û—Ç–ª–∏—á–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"
    elif silhouette_val > 0.5:
        interpretation = "–†–∞–∑—É–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"
    elif silhouette_val > 0.25:
        interpretation = "–°–ª–∞–±–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"
    else:
        interpretation = "–ù–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è"
    print(f"   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {interpretation}")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∏–ø–∞—Ö —Å–≤—è–∑–µ–π
    print(f"\nüìã –û–°–û–ë–ï–ù–ù–û–°–¢–ò LINKAGE –¢–ò–ü–û–í:")
    linkage_info = {
        'ward': "–ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç –¥–∏—Å–ø–µ—Ä—Å–∏—é –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–µ–≤–∫–ª–∏–¥–æ–≤–∞ –º–µ—Ç—Ä–∏–∫–∞)",
        'average': "–°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –≤—Å–µ–º–∏ —Ç–æ—á–∫–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)",
        'complete': "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)",
        'single': "–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (–∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)"
    }
    print(f"   {linkage_type}: {linkage_info.get(linkage_type, '')}")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö
    print(f"\nüîç –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ö–õ–ê–°–¢–ï–†–ê–•:")
    unique_labels = np.unique(labels)
    for i in unique_labels:
        cluster_texts = [texts[j] for j, label in enumerate(labels) if label == i]
        print(f"üî∏ –ö–ª–∞—Å—Ç–µ—Ä {i}: {len(cluster_texts)} —Ç–µ–∫—Å—Ç–æ–≤")
        if len(cluster_texts) > 0:
            for text in cluster_texts[:2]:
                print(f"   - {text[:60]}..." if len(text) > 60 else f"   - {text}")
            if len(cluster_texts) > 2:
                print(f"   ... –∏ –µ—â–µ {len(cluster_texts) - 2} —Ç–µ–∫—Å—Ç–æ–≤")
        print()

    return labels, metrics


if __name__ == "__main__":
    texts = get_texts()
    true_labels = get_labels()

    print("üöÄ AGGLOMERATIVE CLUSTERING –î–õ–Ø –¢–ï–ö–°–¢–û–í")
    print("=" * 60)

    # –í–∞—Ä–∏–∞–Ω—Ç 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –≤–Ω–µ—à–Ω–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    print("üéØ –í–ê–†–ò–ê–ù–¢ 1: –ü–û–õ–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –° –ú–ï–¢–†–ò–ö–ê–ú–ò")
    best_by_int, best_by_ext = compare_agglomerative_clustering(
        texts, true_labels, max_k=5,
        linkage_types=['ward', 'average', 'complete', 'single']
    )

    # –í–∞—Ä–∏–∞–Ω—Ç 2: –ë—ã—Å—Ç—Ä–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
    print("\nüéØ –í–ê–†–ò–ê–ù–¢ 2: –ë–´–°–¢–†–ê–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø")
    if best_by_int:
        labels, metrics = simple_agglomerative_cluster(
            texts,
            n_clusters=best_by_int['k'],
            linkage_type=best_by_int['linkage']
        )
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ª—É—á—à–∏—Ö
        labels, metrics = simple_agglomerative_cluster(
            texts,
            n_clusters=3,
            linkage_type='average'
        )