from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.mixture import GaussianMixture
from sklearn.metrics import (silhouette_score, calinski_harabasz_score,
                             davies_bouldin_score, adjusted_rand_score,
                             normalized_mutual_info_score, v_measure_score,
                             homogeneity_score, completeness_score)
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import numpy as np
import time

from util.decribe import get_labels, get_texts


def compare_gaussian_mixture(texts, true_labels=None, max_k=6, covariance_types=None):
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ GaussianMixture —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü
    """
    vectorizer = TfidfVectorizer(max_features=500)
    X = vectorizer.fit_transform(texts)
    X_dense = X.toarray()

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è GaussianMixture (–≤–∞–∂–Ω–æ –¥–ª—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_dense)

    has_true_labels = true_labels is not None

    if covariance_types is None:
        covariance_types = ['full', 'tied', 'diag', 'spherical']

    if has_true_labels:
        print("üî¨ GAUSSIAN MIXTURE –° –í–ù–£–¢–†–ï–ù–ù–ò–ú–ò –ò –í–ù–ï–®–ù–ò–ú–ò –ú–ï–¢–†–ò–ö–ê–ú–ò:")
        print("k\tCovariance\tSilhouette\tCalinski\tDavies-B\tARI\t\tNMI\t\tV-measure\tConverged")
        print("-" * 115)
    else:
        print("üî¨ GAUSSIAN MIXTURE –° –í–ù–£–¢–†–ï–ù–ù–ò–ú–ò –ú–ï–¢–†–ò–ö–ê–ú–ò:")
        print("k\tCovariance\tSilhouette\tCalinski\tDavies-B\tConverged")
        print("-" * 85)

    results = []

    for k in range(2, max_k + 1):
        for covariance_type in covariance_types:
            try:
                # GaussianMixture –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
                gmm = GaussianMixture(
                    n_components=k,
                    covariance_type=covariance_type,
                    random_state=42,
                    max_iter=100,
                    n_init=3
                )
                # –ú—è–≥–∫–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏
                soft_labels = gmm.fit_predict(X_scaled)
                # –ñ–µ—Å—Ç–∫–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –º–µ—Ç—Ä–∏–∫
                hard_labels = gmm.predict(X_scaled)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å
                converged = gmm.converged_
                n_iter = gmm.n_iter_

                # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                silhouette = silhouette_score(X_dense, hard_labels)
                calinski = calinski_harabasz_score(X_dense, hard_labels)
                davies = davies_bouldin_score(X_dense, hard_labels)

                if has_true_labels:
                    # –í–Ω–µ—à–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                    ari = adjusted_rand_score(true_labels, hard_labels)
                    nmi = normalized_mutual_info_score(true_labels, hard_labels)
                    v_measure = v_measure_score(true_labels, hard_labels)

                    print(f"{k}\t{covariance_type}\t\t{silhouette:.3f}\t\t{calinski:.3f}\t\t{davies:.3f}\t\t"
                          f"{ari:.3f}\t\t{nmi:.3f}\t\t{v_measure:.3f}\t\t{converged}")
                else:
                    print(f"{k}\t{covariance_type}\t\t{silhouette:.3f}\t\t{calinski:.3f}\t\t{davies:.3f}\t\t"
                          f"{converged}")

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏
                probabilities = gmm.predict_proba(X_scaled)

                results.append({
                    'k': k,
                    'covariance_type': covariance_type,
                    'silhouette': silhouette,
                    'calinski': calinski,
                    'davies': davies,
                    'ari': ari if has_true_labels else -1,
                    'nmi': nmi if has_true_labels else -1,
                    'v_measure': v_measure if has_true_labels else -1,
                    'hard_labels': hard_labels,
                    'soft_labels': soft_labels,
                    'probabilities': probabilities,
                    'converged': converged,
                    'n_iter': n_iter,
                    'bic': gmm.bic(X_scaled),
                    'aic': gmm.aic(X_scaled),
                    'gmm': gmm
                })

            except Exception as e:
                print(f"{k}\t{covariance_type}\t\tERROR: {str(e)[:30]}...")

    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    if results:
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ö–æ–¥–∏–≤—à–∏–µ—Å—è –º–æ–¥–µ–ª–∏
        converged_results = [r for r in results if r['converged']]
        if converged_results:
            best_by_silhouette = max(converged_results, key=lambda x: x['silhouette'])
            best_by_bic = min(converged_results, key=lambda x: x['bic'])  # BIC - —á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ

            if has_true_labels:
                best_by_ari = max(converged_results, key=lambda x: x['ari'])

            print(f"\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            print(f"   –ü–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º –º–µ—Ç—Ä–∏–∫–∞–º: k={best_by_silhouette['k']}, "
                  f"covariance={best_by_silhouette['covariance_type']} "
                  f"(Silhouette: {best_by_silhouette['silhouette']:.3f})")
            print(f"   –ü–æ BIC: k={best_by_bic['k']}, covariance={best_by_bic['covariance_type']} "
                  f"(BIC: {best_by_bic['bic']:.1f})")
            if has_true_labels:
                print(f"   –ü–æ –≤–Ω–µ—à–Ω–∏–º –º–µ—Ç—Ä–∏–∫–∞–º: k={best_by_ari['k']}, "
                      f"covariance={best_by_ari['covariance_type']} "
                      f"(ARI: {best_by_ari['ari']:.3f})")
        else:
            print(f"\n‚ö†Ô∏è  –ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Å–æ—à–ª–∞—Å—å")
            best_by_silhouette = best_by_bic = best_by_ari = None
    else:
        print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é")
        best_by_silhouette = best_by_bic = best_by_ari = None

    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏
    if has_true_labels and results:
        _plot_gmm_metrics(results, texts, true_labels, best_by_silhouette, best_by_ari, best_by_bic)
    elif results:
        _plot_gmm_internal_metrics(results, best_by_silhouette, best_by_bic)

    if has_true_labels and converged_results:
        return best_by_silhouette, best_by_ari, best_by_bic
    elif converged_results:
        return best_by_silhouette, best_by_bic
    else:
        return None, None, None


def _plot_gmm_metrics(results, texts, true_labels, best_silhouette, best_ari, best_bic):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è GaussianMixture —Å–æ –≤—Å–µ–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    covariance_types = sorted(set(r['covariance_type'] for r in results))
    k_values = sorted(set(r['k'] for r in results))

    # –ì—Ä–∞—Ñ–∏–∫ 1: Silhouette Score –¥–ª—è —Ä–∞–∑–Ω—ã—Ö covariance types
    for cov_type in covariance_types:
        cov_data = [r for r in results if r['covariance_type'] == cov_type and r['converged']]
        if cov_data:
            k_vals = [r['k'] for r in cov_data]
            silhouette_vals = [r['silhouette'] for r in cov_data]
            ax1.plot(k_vals, silhouette_vals, 'o-', linewidth=2, markersize=6,
                     label=f'{cov_type}')

    if best_silhouette:
        ax1.axvline(x=best_silhouette['k'], color='red', linestyle='--', alpha=0.7,
                    label=f'–õ—É—á—à–µ–µ k={best_silhouette["k"]}')

    ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax1.set_ylabel('Silhouette Score')
    ax1.set_title('GAUSSIAN MIXTURE: SILHOUETTE SCORE\n(‚Üë –ª—É—á—à–µ)')
    ax1.grid(True, alpha=0.3)
    ax1.legend()

    # –ì—Ä–∞—Ñ–∏–∫ 2: BIC (Bayesian Information Criterion)
    for cov_type in covariance_types:
        cov_data = [r for r in results if r['covariance_type'] == cov_type and r['converged']]
        if cov_data:
            k_vals = [r['k'] for r in cov_data]
            bic_vals = [r['bic'] for r in cov_data]
            ax2.plot(k_vals, bic_vals, 'o-', linewidth=2, markersize=6,
                     label=f'{cov_type}')

    if best_bic:
        ax2.axvline(x=best_bic['k'], color='blue', linestyle='--', alpha=0.7,
                    label=f'–õ—É—á—à–µ–µ k={best_bic["k"]} (BIC)')

    ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax2.set_ylabel('BIC Score')
    ax2.set_title('GAUSSIAN MIXTURE: BAYESIAN INFORMATION CRITERION\n(‚Üì –ª—É—á—à–µ)')
    ax2.grid(True, alpha=0.3)
    ax2.legend()

    # –ì—Ä–∞—Ñ–∏–∫ 3: –í–Ω–µ—à–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (ARI)
    if best_ari:
        for cov_type in covariance_types:
            cov_data = [r for r in results if r['covariance_type'] == cov_type and r['converged'] and r['ari'] > -1]
            if cov_data:
                k_vals = [r['k'] for r in cov_data]
                ari_vals = [r['ari'] for r in cov_data]
                ax3.plot(k_vals, ari_vals, 'o-', linewidth=2, markersize=6,
                         label=f'{cov_type}')

    ax3.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax3.set_ylabel('ARI Score')
    ax3.set_title('GAUSSIAN MIXTURE: ADJUSTED RAND INDEX\n(‚Üë –ª—É—á—à–µ)')
    ax3.grid(True, alpha=0.3)
    ax3.legend()

    # –ì—Ä–∞—Ñ–∏–∫ 4: –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    times = {}
    vectorizer = TfidfVectorizer(max_features=500)
    X = vectorizer.fit_transform(texts)
    X_dense = X.toarray()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_dense)

    for cov_type in covariance_types:
        cov_times = []
        for k in k_values:
            try:
                gmm = GaussianMixture(n_components=k, covariance_type=cov_type,
                                      random_state=42, max_iter=50)
                start_time = time.time()
                gmm.fit(X_scaled)
                cov_times.append(time.time() - start_time)
            except:
                cov_times.append(np.nan)

        times[cov_type] = cov_times

    for cov_type, time_vals in times.items():
        ax4.plot(k_values, time_vals, 'o-', linewidth=2, markersize=6, label=cov_type)

    ax4.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax4.set_ylabel('–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (—Å–µ–∫—É–Ω–¥—ã)')
    ax4.set_title('GAUSSIAN MIXTURE: –í–†–ï–ú–Ø –í–´–ü–û–õ–ù–ï–ù–ò–Ø')
    ax4.grid(True, alpha=0.3)
    ax4.legend()

    plt.tight_layout()
    plt.show()


def _plot_gmm_internal_metrics(results, best_silhouette, best_bic):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –º–µ—Ç—Ä–∏–∫
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))

    covariance_types = sorted(set(r['covariance_type'] for r in results))
    k_values = sorted(set(r['k'] for r in results))

    # –ì—Ä–∞—Ñ–∏–∫ 1: Silhouette Score
    for cov_type in covariance_types:
        cov_data = [r for r in results if r['covariance_type'] == cov_type and r['converged']]
        if cov_data:
            k_vals = [r['k'] for r in cov_data]
            silhouette_vals = [r['silhouette'] for r in cov_data]
            ax1.plot(k_vals, silhouette_vals, 'o-', linewidth=2, markersize=6,
                     label=f'{cov_type}')

    if best_silhouette:
        ax1.axvline(x=best_silhouette['k'], color='red', linestyle='--', alpha=0.7,
                    label=f'–õ—É—á—à–µ–µ k={best_silhouette["k"]}')

    ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax1.set_ylabel('Silhouette Score')
    ax1.set_title('GAUSSIAN MIXTURE: SILHOUETTE SCORE\n(‚Üë –ª—É—á—à–µ)')
    ax1.grid(True, alpha=0.3)
    ax1.legend()

    # –ì—Ä–∞—Ñ–∏–∫ 2: BIC –∏ AIC
    for cov_type in covariance_types:
        cov_data = [r for r in results if r['covariance_type'] == cov_type and r['converged']]
        if cov_data:
            k_vals = [r['k'] for r in cov_data]
            bic_vals = [r['bic'] for r in cov_data]
            aic_vals = [r['aic'] for r in cov_data]

            ax2.plot(k_vals, bic_vals, 'o-', linewidth=2, markersize=6,
                     label=f'BIC ({cov_type})')
            ax2.plot(k_vals, aic_vals, 'o--', linewidth=1, markersize=4,
                     label=f'AIC ({cov_type})', alpha=0.7)

    if best_bic:
        ax2.axvline(x=best_bic['k'], color='blue', linestyle='--', alpha=0.7,
                    label=f'–õ—É—á—à–µ–µ k={best_bic["k"]}')

    ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (k)')
    ax2.set_ylabel('BIC / AIC Score')
    ax2.set_title('GAUSSIAN MIXTURE: BIC –ò AIC\n(‚Üì –ª—É—á—à–µ)')
    ax2.grid(True, alpha=0.3)
    ax2.legend()

    plt.tight_layout()
    plt.show()


# –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ GaussianMixture
def simple_gmm_cluster(texts, n_components=3, covariance_type='full'):
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤ —Å GaussianMixture (–º—è–≥–∫–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ)
    """
    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
    vectorizer = TfidfVectorizer(max_features=500)
    X = vectorizer.fit_transform(texts)
    X_dense = X.toarray()

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è GaussianMixture
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_dense)

    # GaussianMixture –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
    gmm = GaussianMixture(
        n_components=n_components,
        covariance_type=covariance_type,
        random_state=42,
        max_iter=100
    )

    # –ú—è–≥–∫–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏
    soft_labels = gmm.fit_predict(X_scaled)
    # –ñ–µ—Å—Ç–∫–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –º–µ—Ç—Ä–∏–∫
    hard_labels = gmm.predict(X_scaled)
    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
    probabilities = gmm.predict_proba(X_scaled)

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    metrics = {
        'silhouette': silhouette_score(X_dense, hard_labels),
        'calinski_harabasz': calinski_harabasz_score(X_dense, hard_labels),
        'davies_bouldin': davies_bouldin_score(X_dense, hard_labels),
        'bic': gmm.bic(X_scaled),
        'aic': gmm.aic(X_scaled),
        'converged': gmm.converged_,
        'n_iter': gmm.n_iter_,
        'covariance_type': covariance_type
    }

    # –ü—Ä–æ—Å—Ç–æ–π –≤—ã–≤–æ–¥
    print(f"üìä GaussianMixture –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ {n_components} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
    print(f"‚öôÔ∏è  –ü–ê–†–ê–ú–ï–¢–†–´: covariance_type={covariance_type}")
    print(f"üéØ –ú–ï–¢–†–ò–ö–ò:")
    print(f"   Silhouette Score: {metrics['silhouette']:.3f}")
    print(f"   Calinski-Harabasz: {metrics['calinski_harabasz']:.3f}")
    print(f"   Davies-Bouldin: {metrics['davies_bouldin']:.3f}")
    print(f"   BIC: {metrics['bic']:.1f}")
    print(f"   AIC: {metrics['aic']:.1f}")
    print(f"   –°—Ö–æ–¥–∏–º–æ—Å—Ç—å: {metrics['converged']} (–∏—Ç–µ—Ä–∞—Ü–∏–π: {metrics['n_iter']})")

    # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è Silhouette Score
    silhouette_val = metrics['silhouette']
    if silhouette_val > 0.7:
        interpretation = "–û—Ç–ª–∏—á–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"
    elif silhouette_val > 0.5:
        interpretation = "–†–∞–∑—É–º–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"
    elif silhouette_val > 0.25:
        interpretation = "–°–ª–∞–±–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"
    else:
        interpretation = "–ù–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è"
    print(f"   –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {interpretation}")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∏–ø–∞—Ö –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü
    print(f"\nüìã –¢–ò–ü–´ –ö–û–í–ê–†–ò–ê–¶–ò–û–ù–ù–´–• –ú–ê–¢–†–ò–¶:")
    cov_info = {
        'full': "–ü–æ–ª–Ω–∞—è –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞",
        'tied': "–û–¥–Ω–∞ –æ–±—â–∞—è –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤",
        'diag': "–î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞",
        'spherical': "–°—Ñ–µ—Ä–∏—á–µ—Å–∫–∞—è –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (–æ–¥–∏–Ω–∞–∫–æ–≤–∞—è –ø–æ –≤—Å–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º)"
    }
    print(f"   {covariance_type}: {cov_info.get(covariance_type, '')}")

    # –ê–Ω–∞–ª–∏–∑ –º—è–≥–∫–æ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
    print(f"\nüîÆ –ú–Ø–ì–ö–û–ï –ù–ê–ó–ù–ê–ß–ï–ù–ò–ï –ö–õ–ê–°–¢–ï–†–û–í:")
    print(f"   –ö–∞–∂–¥–∞—è —Ç–æ—á–∫–∞ –∏–º–µ–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∫–æ –≤—Å–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∞–º")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –º—è–≥–∫–æ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–æ—á–µ–∫
    print(f"\nüìä –ü–†–ò–ú–ï–†–´ –í–ï–†–û–Ø–¢–ù–û–°–¢–ï–ô –ü–†–ò–ù–ê–î–õ–ï–ñ–ù–û–°–¢–ò (–ø–µ—Ä–≤—ã–µ 5 —Ç–æ—á–µ–∫):")
    print("–¢–æ—á–∫–∞\t" + "\t".join([f"–ö–ª–∞—Å—Ç–µ—Ä {i}" for i in range(n_components)]))
    for i in range(min(5, len(probabilities))):
        prob_str = "\t".join([f"{p:.3f}" for p in probabilities[i]])
        print(f"{i}\t{prob_str}")

    # –ê–Ω–∞–ª–∏–∑ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    max_probs = np.max(probabilities, axis=1)
    confidence_stats = {
        'high_confidence': np.sum(max_probs > 0.9) / len(max_probs) * 100,
        'medium_confidence': np.sum((max_probs > 0.7) & (max_probs <= 0.9)) / len(max_probs) * 100,
        'low_confidence': np.sum(max_probs <= 0.7) / len(max_probs) * 100
    }

    print(f"\nüéØ –£–í–ï–†–ï–ù–ù–û–°–¢–¨ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:")
    print(f"   –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (>0.9): {confidence_stats['high_confidence']:.1f}% —Ç–æ—á–µ–∫")
    print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0.7-0.9): {confidence_stats['medium_confidence']:.1f}% —Ç–æ—á–µ–∫")
    print(f"   –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (‚â§0.7): {confidence_stats['low_confidence']:.1f}% —Ç–æ—á–µ–∫")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö (–∂–µ—Å—Ç–∫–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ)
    print(f"\nüîç –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ö–õ–ê–°–¢–ï–†–ê–• (–∂–µ—Å—Ç–∫–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ):")
    unique_labels = np.unique(hard_labels)
    for i in unique_labels:
        cluster_texts = [texts[j] for j, label in enumerate(hard_labels) if label == i]
        avg_confidence = np.mean(max_probs[hard_labels == i])

        print(f"üî∏ –ö–ª–∞—Å—Ç–µ—Ä {i}: {len(cluster_texts)} —Ç–µ–∫—Å—Ç–æ–≤ (—Å—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.3f})")
        if len(cluster_texts) > 0:
            for text in cluster_texts[:2]:
                print(f"   - {text[:60]}..." if len(text) > 60 else f"   - {text}")
            if len(cluster_texts) > 2:
                print(f"   ... –∏ –µ—â–µ {len(cluster_texts) - 2} —Ç–µ–∫—Å—Ç–æ–≤")
        print()

    return hard_labels, soft_labels, probabilities, metrics, gmm


if __name__ == "__main__":
    texts = get_texts()
    true_labels = get_labels()

    print("üöÄ GAUSSIAN MIXTURE –î–õ–Ø –¢–ï–ö–°–¢–û–í")
    print("=" * 60)

    # –í–∞—Ä–∏–∞–Ω—Ç 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –≤–Ω–µ—à–Ω–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    print("üéØ –í–ê–†–ò–ê–ù–¢ 1: –ü–û–õ–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –° –ú–ï–¢–†–ò–ö–ê–ú–ò")
    best_by_int, best_by_ext, best_by_bic = compare_gaussian_mixture(
        texts, true_labels, max_k=5,
        covariance_types=['full', 'tied', 'diag', 'spherical']
    )

    # –í–∞—Ä–∏–∞–Ω—Ç 2: –ë—ã—Å—Ç—Ä–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
    print("\nüéØ –í–ê–†–ò–ê–ù–¢ 2: –ë–´–°–¢–†–ê–Ø –ö–õ–ê–°–¢–ï–†–ò–ó–ê–¶–ò–Ø –° –ú–Ø–ì–ö–ò–ú –ù–ê–ó–ù–ê–ß–ï–ù–ò–ï–ú")
    if best_by_int:
        hard_labels, soft_labels, probabilities, metrics, gmm = simple_gmm_cluster(
            texts,
            n_components=best_by_int['k'],
            covariance_type=best_by_int['covariance_type']
        )
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ª—É—á—à–∏—Ö
        hard_labels, soft_labels, probabilities, metrics, gmm = simple_gmm_cluster(
            texts,
            n_components=3,
            covariance_type='full'
        )